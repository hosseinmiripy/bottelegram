{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hosseinmiripy/bottelegram/blob/main/%D8%A7%D8%B3%D9%85%D8%A7%D8%B1%D8%AA_%D9%85%D8%A7%D9%86%DB%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "ğŸ‹ Smart Money Whale Hunter - Professional Edition v2.1 (ENHANCED)\n",
        "==================================================================\n",
        "âœ… Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù† USDT Dominance\n",
        "âœ… Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù† Market Phase Detection\n",
        "âœ… Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù† Ø­Ø¯Ø§Ù‚Ù„ ØªÙØ§ÙˆØª Ø§Ù…ØªÛŒØ§Ø² (25)\n",
        "âœ… Ø¨Ù‡Ø¨ÙˆØ¯ Stop Loss Validation\n",
        "âœ… Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø±ÛŒØ³Ú© Ø¨Ù‡ 3%\n",
        "âœ… Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„\n",
        "âœ… Position Size Recommendation\n",
        "\"\"\"\n",
        "\n",
        "# ==================== Ø¨Ø®Ø´ 1: Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ ====================\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def install_requirements():\n",
        "    \"\"\"Ù†ØµØ¨ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ø±ÙØ¹ Ù…Ø´Ú©Ù„ Kaleido\"\"\"\n",
        "    packages = {\n",
        "        'core': ['pandas', 'numpy', 'scipy', 'scikit-learn'],\n",
        "        'data': ['ccxt', 'requests'],\n",
        "        'analysis': ['ta'],\n",
        "        'visualization': ['matplotlib', 'seaborn', 'mplfinance', 'plotly'],\n",
        "        'system': ['psutil', 'python-dateutil'],\n",
        "    }\n",
        "\n",
        "    print(\"ğŸ“¦ Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ...\")\n",
        "    for category, libs in packages.items():\n",
        "        for lib in libs:\n",
        "            subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', lib],\n",
        "                          capture_output=True)\n",
        "\n",
        "    # Ù†ØµØ¨ Kaleido Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§\n",
        "    print(\"ğŸ¨ Ù†ØµØ¨ Kaleido...\")\n",
        "    try:\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'kaleido==0.2.1'],\n",
        "                      check=True, capture_output=True)\n",
        "        print(\"âœ… Kaleido Ù†ØµØ¨ Ø´Ø¯\")\n",
        "    except:\n",
        "        print(\"âš ï¸ Kaleido Ù†ØµØ¨ Ù†Ø´Ø¯ - Ø§Ø² matplotlib Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯\")\n",
        "\n",
        "    print(\"ğŸ”§ Ù†ØµØ¨ ØªÙ„Ú¯Ø±Ø§Ù…...\")\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', 'python-telegram-bot'],\n",
        "                   capture_output=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', 'telegram'],\n",
        "                   capture_output=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'python-telegram-bot==20.8'],\n",
        "                   check=True)\n",
        "\n",
        "    print(\"âœ… Ù†ØµØ¨ Ú©Ø§Ù…Ù„ Ø´Ø¯\\n\")\n",
        "\n",
        "\n",
        "try:\n",
        "    install_requirements()\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù†ØµØ¨: {e}\")\n",
        "\n",
        "# ==================== Ø¨Ø®Ø´ 2: Import ====================\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import logging\n",
        "import warnings\n",
        "import hashlib\n",
        "import pickle\n",
        "import gc\n",
        "import traceback\n",
        "import math\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "from dataclasses import dataclass, field\n",
        "from collections import defaultdict, deque\n",
        "from threading import Lock\n",
        "from io import BytesIO\n",
        "import tempfile\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ccxt\n",
        "import ta\n",
        "import requests\n",
        "import psutil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import mplfinance as mpf\n",
        "from matplotlib.patches import Rectangle, FancyBboxPatch, Polygon\n",
        "import seaborn as sns\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "TELEGRAM_AVAILABLE = False\n",
        "try:\n",
        "    from telegram import Update, InputFile\n",
        "    from telegram.ext import Application, CommandHandler, ContextTypes\n",
        "    TELEGRAM_AVAILABLE = True\n",
        "    print(\"âœ… ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯\")\n",
        "except ImportError as e:\n",
        "    print(f\"âš ï¸ ØªÙ„Ú¯Ø±Ø§Ù… ØºÛŒØ±ÙØ¹Ø§Ù„: {e}\")\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==================== Ø¨Ø®Ø´ 3: ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø­ÛŒØ· ====================\n",
        "COLAB_ENV = False\n",
        "try:\n",
        "    import google.colab\n",
        "    COLAB_ENV = True\n",
        "    from google.colab import drive\n",
        "\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "    BASE_DIR = '/content/drive/MyDrive/smart_money_whale_hunter'\n",
        "    print(\"ğŸŒŸ Ù…Ø­ÛŒØ· Google Colab\")\n",
        "except:\n",
        "    BASE_DIR = os.path.dirname(os.path.abspath(__file__)) if '__file__' in globals() else os.getcwd()\n",
        "    print(\"ğŸ–¥ï¸ Ù…Ø­ÛŒØ· Ù…Ø­Ù„ÛŒ\")\n",
        "\n",
        "for dir_name in ['logs', 'charts', 'cache/ohlcv', 'cache/disk', 'temp']:\n",
        "    os.makedirs(f\"{BASE_DIR}/{dir_name}\", exist_ok=True)\n",
        "\n",
        "print(f\"ğŸ“‚ BASE_DIR: {BASE_DIR}\\n\")\n",
        "\n",
        "# ==================== Ø¨Ø®Ø´ 4: Ù„Ø§Ú¯ÛŒÙ†Ú¯ ====================\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(f\"{BASE_DIR}/logs/whale_hunter.log\", encoding='utf-8'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ==================== Ø¨Ø®Ø´ 5: ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ù„ÛŒ ====================\n",
        "TELEGRAM_BOT_TOKEN = \"7307185304:AAF9zG3vM0Pc74WkiIDVEnRxu41OJYdyql8\"\n",
        "TELEGRAM_CHANNEL_ID = \"@finance_hossein\"\n",
        "\n",
        "ADMIN_USERS = [\"@hosseinmiri3\", 1150906790]  # ÛŒÙˆØ²Ø±Ù†ÛŒÙ… Ùˆ ÛŒÙˆØ²Ø± Ø¢ÛŒØ¯ÛŒ Ø§Ø¯Ù…ÛŒÙ†\n",
        "\n",
        "BOT_SETTINGS = {\n",
        "    'max_memory_cache_size': 300,\n",
        "    'cache_max_age_hours': 2,\n",
        "    'cleanup_interval_hours': 1,\n",
        "    'min_score_difference': 25,  # â¬…ï¸ Ø¬Ø¯ÛŒØ¯\n",
        "    'max_risk_percent': 3.0,     # â¬…ï¸ Ø¬Ø¯ÛŒØ¯\n",
        "    'sl_buffer_percent': 0.5,    # â¬…ï¸ Ø¬Ø¯ÛŒØ¯\n",
        "}\n",
        "\n",
        "# ==================== Ø¨Ø®Ø´ 5: ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ù„ÛŒ - Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ ====================\n",
        "\n",
        "# Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒØ¨Ù†Ø¯ÛŒ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ - KuCoin Ø¯Ø± Ø§ÙˆÙ„ÙˆÛŒØª Ø§ÙˆÙ„\n",
        "EXCHANGES_CONFIG = {\n",
        "    # ğŸ¥‡ Ø§ÙˆÙ„ÙˆÛŒØª Ø§ÙˆÙ„: KuCoin - ØªÙ†ÙˆØ¹ Ú©ÙˆÛŒÙ† Ø¨Ø§Ù„Ø§ Ùˆ Ù¾Ø§ÛŒØ¯Ø§Ø±\n",
        "    'kucoin': {\n",
        "        'class': ccxt.kucoin,\n",
        "        'max_requests_per_minute': 20,  # Ú©Ø§Ù‡Ø´ Ø§Ø² 30 Ø¨Ø±Ø§ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ\n",
        "        'weight': 3.0,  # Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† ÙˆØ²Ù†\n",
        "        'cooldown': 45,\n",
        "        'features': ['spot'],\n",
        "        'reliable': True,\n",
        "    },\n",
        "\n",
        "    # ğŸ¥ˆ Ø§ÙˆÙ„ÙˆÛŒØª Ø¯ÙˆÙ…: OKX - Ø­Ø¬Ù… Ø¨Ø§Ù„Ø§ Ùˆ API Ù¾Ø§ÛŒØ¯Ø§Ø±\n",
        "    'okx': {\n",
        "        'class': ccxt.okx,\n",
        "        'max_requests_per_minute': 15,  # Ú©Ø§Ù‡Ø´ Ø§Ø² 20\n",
        "        'weight': 2.8,\n",
        "        'cooldown': 50,\n",
        "        'features': ['spot', 'derivatives'],\n",
        "        'reliable': True,\n",
        "    },\n",
        "\n",
        "    # ğŸ¥‰ Ø§ÙˆÙ„ÙˆÛŒØª Ø³ÙˆÙ…: Gate.io - ØªÙ†ÙˆØ¹ altcoin Ø¹Ø§Ù„ÛŒ\n",
        "    'gateio': {\n",
        "        'class': ccxt.gateio,\n",
        "        'max_requests_per_minute': 25,  # Ú©Ø§Ù‡Ø´ Ø§Ø² 50\n",
        "        'weight': 2.5,\n",
        "        'cooldown': 45,\n",
        "        'features': ['spot', 'derivatives'],\n",
        "        'reliable': True,\n",
        "    },\n",
        "\n",
        "    # 4ï¸âƒ£ Bitget - ØµØ±Ø§ÙÛŒ Ø¯Ø± Ø­Ø§Ù„ Ø±Ø´Ø¯\n",
        "    'bitget': {\n",
        "        'class': ccxt.bitget,\n",
        "        'max_requests_per_minute': 30,  # Ú©Ø§Ù‡Ø´ Ø§Ø² 60\n",
        "        'weight': 2.2,\n",
        "        'cooldown': 40,\n",
        "        'features': ['spot', 'derivatives'],\n",
        "        'reliable': True,\n",
        "    },\n",
        "\n",
        "    # 5ï¸âƒ£ MEXC - altcoin Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯\n",
        "    'mexc': {\n",
        "        'class': ccxt.mexc,\n",
        "        'max_requests_per_minute': 20,  # Ú©Ø§Ù‡Ø´ Ø§Ø² 40\n",
        "        'weight': 2.0,\n",
        "        'cooldown': 50,\n",
        "        'features': ['spot'],\n",
        "        'reliable': True,\n",
        "    },\n",
        "\n",
        "    # 6ï¸âƒ£ Bybit - Ø¨Ø§ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø´Ø¯ÛŒØ¯\n",
        "    'bybit': {\n",
        "        'class': ccxt.bybit,\n",
        "        'max_requests_per_minute': 8,  # Ú©Ø§Ù‡Ø´ Ø´Ø¯ÛŒØ¯ Ø§Ø² 60\n",
        "        'weight': 1.5,  # Ú©Ø§Ù‡Ø´ ÙˆØ²Ù†\n",
        "        'cooldown': 120,  # Ø§ÙØ²Ø§ÛŒØ´ Ú©ÙˆÙ„Ø¯Ø§ÙˆÙ†\n",
        "        'features': ['spot', 'derivatives'],\n",
        "        'reliable': False,  # ØªØºÛŒÛŒØ± Ø¨Ù‡ False\n",
        "    },\n",
        "\n",
        "    # 7ï¸âƒ£ Huobi (HTX) - Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª SSL\n",
        "    'huobi': {\n",
        "        'class': ccxt.huobi,\n",
        "        'max_requests_per_minute': 15,  # Ú©Ø§Ù‡Ø´ Ø§Ø² 50\n",
        "        'weight': 1.2,\n",
        "        'cooldown': 90,\n",
        "        'features': ['spot', 'derivatives'],\n",
        "        'reliable': False,  # ØªØºÛŒÛŒØ± Ø¨Ù‡ False\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "exchange_state = {}\n",
        "exchange_data = {}\n",
        "for ex_id in EXCHANGES_CONFIG:\n",
        "    state = {\n",
        "        'request_count': 0,\n",
        "        'last_reset_time': time.time(),\n",
        "        'in_cooldown': False,\n",
        "        'cooldown_until': 0,\n",
        "        'success_count': 0,\n",
        "        'fail_count': 0,\n",
        "    }\n",
        "    exchange_state[ex_id] = state\n",
        "    exchange_data[ex_id] = state\n",
        "\n",
        "request_lock = Lock()\n",
        "request_count_lock = request_lock\n",
        "\n",
        "memory_cache = {}\n",
        "memory_cache_time = {}\n",
        "memory_cache_access_time = {}\n",
        "CACHE_MAX_SIZE = 300\n",
        "CACHE_MAX_AGE_HOURS = 2\n",
        "last_cleanup = time.time()\n",
        "\n",
        "# ==================== Ø¨Ø®Ø´ 6: Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡ ====================\n",
        "@dataclass\n",
        "class OrderBlock:\n",
        "    high: float\n",
        "    low: float\n",
        "    time: int\n",
        "    bias: str\n",
        "    strength: float\n",
        "    touched: bool = False\n",
        "    volume: float = 0\n",
        "\n",
        "@dataclass\n",
        "class FairValueGap:\n",
        "    top: float\n",
        "    bottom: float\n",
        "    time: int\n",
        "    bias: str\n",
        "    filled: bool = False\n",
        "    size: float = 0\n",
        "\n",
        "@dataclass\n",
        "class MarketStructure:\n",
        "    type: str\n",
        "    direction: str\n",
        "    price: float\n",
        "    time: int\n",
        "    strength: float\n",
        "    confirmed: bool = True\n",
        "\n",
        "@dataclass\n",
        "class WhaleActivity:\n",
        "    timestamp: int\n",
        "    volume: float\n",
        "    price: float\n",
        "    type: str\n",
        "    strength: float\n",
        "    impact: float = 0\n",
        "\n",
        "@dataclass\n",
        "class LiquidityZone:\n",
        "    price: float\n",
        "    type: str\n",
        "    strength: float\n",
        "    time: int\n",
        "\n",
        "@dataclass\n",
        "class TradingSignal:\n",
        "    \"\"\"Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ - Ù†Ø³Ø®Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡\"\"\"\n",
        "    symbol: str\n",
        "    direction: str\n",
        "    entry_price: float\n",
        "    stop_loss: float\n",
        "    targets: List[float]\n",
        "    confidence: float\n",
        "    timeframe: str\n",
        "    reasons: List[str]\n",
        "    market_context: Dict\n",
        "    timestamp: datetime\n",
        "    risk_reward: float = 0\n",
        "    chart_path: Optional[str] = None\n",
        "    position_size_recommendation: str = \"\"  # â¬…ï¸ Ø¬Ø¯ÛŒØ¯\n",
        "    risk_percent: float = 0.0  # â¬…ï¸ Ø¬Ø¯ÛŒØ¯\n",
        "\n",
        "    def __post_init__(self):\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ R:R\n",
        "        if self.direction == 'LONG':\n",
        "            self.risk_reward = (self.targets[0] - self.entry_price) / (self.entry_price - self.stop_loss)\n",
        "        else:\n",
        "            self.risk_reward = (self.entry_price - self.targets[0]) / (self.stop_loss - self.entry_price)\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ø±ØµØ¯ Ø±ÛŒØ³Ú©\n",
        "        self.risk_percent = abs(self.stop_loss - self.entry_price) / self.entry_price * 100\n",
        "\n",
        "        # ØªÙˆØµÛŒÙ‡ Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ù‡\n",
        "        self.position_size_recommendation = (\n",
        "            f\"Ø¨Ø§ Ø±ÛŒØ³Ú© 1% Ø³Ø±Ù…Ø§ÛŒÙ‡: Ø­Ø¬Ù… = (Ø³Ø±Ù…Ø§ÛŒÙ‡ Ã— 0.01) / (ÙØ§ØµÙ„Ù‡ ØªØ§ SL)\\n\"\n",
        "            f\"Risk per trade: {self.risk_percent:.2f}% | \"\n",
        "            f\"Suggested: Use 1% of capital\"\n",
        "        )\n",
        "\n",
        "# ==================== Ø¨Ø®Ø´ 7: ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ ====================\n",
        "\n",
        "def get_cache_key(*args):\n",
        "    return \"_\".join(str(arg) for arg in args)\n",
        "\n",
        "def clean_memory_cache(max_items=None, force_cleanup=False):\n",
        "    global memory_cache, memory_cache_access_time\n",
        "\n",
        "    if max_items is None:\n",
        "        max_items = BOT_SETTINGS.get('max_memory_cache_size', 300) // 2\n",
        "\n",
        "    if len(memory_cache) > max_items or force_cleanup:\n",
        "        sorted_keys = sorted(\n",
        "            memory_cache_access_time.items(),\n",
        "            key=lambda x: x[1]\n",
        "        )\n",
        "\n",
        "        keys_to_remove = [k for k, _ in sorted_keys[:len(sorted_keys) - max_items]]\n",
        "\n",
        "        for key in keys_to_remove:\n",
        "            if key in memory_cache:\n",
        "                del memory_cache[key]\n",
        "            if key in memory_cache_access_time:\n",
        "                del memory_cache_access_time[key]\n",
        "\n",
        "        logger.info(f\"ğŸ§¹ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ú©Ø´ Ø­Ø§ÙØ¸Ù‡: {len(keys_to_remove)} Ø¢ÛŒØªÙ… Ø­Ø°Ù Ø´Ø¯\")\n",
        "        gc.collect()\n",
        "\n",
        "def validate_data(df):\n",
        "    \"\"\"Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØªÛŒ\"\"\"\n",
        "    if df is None or len(df) < 20:\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± null\n",
        "        null_count = df.isnull().sum().sum()\n",
        "        if null_count > 0:\n",
        "            if null_count < len(df) * 0.03:  # Ú©Ù…ØªØ± Ø§Ø² 3% null Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„\n",
        "                df.ffill(inplace=True)\n",
        "                df.bfill(inplace=True)\n",
        "                if df.isnull().sum().sum() > 0:\n",
        "                    return False\n",
        "            else:\n",
        "                return False\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ ØªØºÛŒÛŒØ±Ø§Øª Ù‚ÛŒÙ…Øª ØºÛŒØ±Ø·Ø¨ÛŒØ¹ÛŒ\n",
        "        price_changes = df['close'].pct_change().abs()\n",
        "        if price_changes.max() > 0.5:  # ØªØºÛŒÛŒØ± Ø¨ÛŒØ´ Ø§Ø² 50% Ù…Ø´Ú©ÙˆÚ© Ø§Ø³Øª\n",
        "            extreme_changes = price_changes[price_changes > 0.25]\n",
        "            if len(extreme_changes) > len(df) * 0.05:  # Ø¨ÛŒØ´ Ø§Ø² 5% ØªØºÛŒÛŒØ±Ø§Øª Ø´Ø¯ÛŒØ¯\n",
        "                return False\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª\n",
        "        zero_volume_ratio= (df['volume'] == 0).sum() / len(df)\n",
        "        if zero_volume_ratio > 0.15:  # Ø¨ÛŒØ´ Ø§Ø² 15% Ø­Ø¬Ù… ØµÙØ± Ù…Ø´Ú©ÙˆÚ© Ø§Ø³Øª\n",
        "            return False\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø±ØªØ¨ Ø¨ÙˆØ¯Ù† Ø²Ù…Ø§Ù†\n",
        "        if not df.index.is_monotonic_increasing:\n",
        "            df.sort_index(inplace=True)\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ù†Ø¨ÙˆØ¯Ù† Ø²Ù…Ø§Ù†\n",
        "        if df.index.duplicated().any():\n",
        "            df = df[~df.index.duplicated(keep='last')]\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ù†Ø·Ù‚ÛŒ Ø¨ÙˆØ¯Ù† Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ (high >= low, close Ø¨ÛŒÙ† high Ùˆ low)\n",
        "        invalid_prices = (df['high'] < df['low']) | (df['close'] > df['high']) | (df['close'] < df['low'])\n",
        "        if invalid_prices.any():\n",
        "            if invalid_prices.sum() < len(df) * 0.02:  # Ú©Ù…ØªØ± Ø§Ø² 2% Ù‚Ø§Ø¨Ù„ ØªØµØ­ÛŒØ­\n",
        "                # ØªØµØ­ÛŒØ­ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±\n",
        "                df.loc[invalid_prices, 'high'] = df.loc[invalid_prices, ['open', 'close']].max(axis=1)\n",
        "                df.loc[invalid_prices, 'low'] = df.loc[invalid_prices, ['open', 'close']].min(axis=1)\n",
        "            else:\n",
        "                return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø¯Ø§Ø¯Ù‡: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "class DataManager:\n",
        "    \"\"\"Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ø§ÙˆÙ„ÙˆÛŒØª KuCoin\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.exchanges = {}\n",
        "        self.failed_exchanges = []\n",
        "\n",
        "    def initialize_exchanges(self):\n",
        "        \"\"\"Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ Ø¨Ø§ Ø§ÙˆÙ„ÙˆÛŒØª KuCoin\"\"\"\n",
        "        logger.info(\"ğŸ”„ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§...\")\n",
        "        logger.info(\"=\" * 60)\n",
        "\n",
        "        # Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒØ¨Ù†Ø¯ÛŒ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§\n",
        "        priority_order = ['kucoin', 'okx', 'gateio', 'bitget', 'mexc', 'bybit', 'huobi']\n",
        "\n",
        "        for ex_id in priority_order:\n",
        "            if ex_id not in EXCHANGES_CONFIG:\n",
        "                continue\n",
        "\n",
        "            config = EXCHANGES_CONFIG[ex_id]\n",
        "            logger.info(f\"ğŸ”— Ø§ØªØµØ§Ù„ Ø¨Ù‡ {ex_id.upper()}...\")\n",
        "\n",
        "            try:\n",
        "                # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø§ÛŒÙ‡\n",
        "                exchange_config = {\n",
        "                    'enableRateLimit': True,\n",
        "                    'timeout': 30000,\n",
        "                    'options': {'defaultType': 'spot'},\n",
        "                    'headers': {\n",
        "                        'User-Agent': 'Mozilla/5.0 (compatible; trading-bot/1.0)'\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø®Ø§Øµ Ù‡Ø± ØµØ±Ø§ÙÛŒ\n",
        "                if ex_id == 'kucoin':\n",
        "                    exchange_config['sandbox'] = False\n",
        "                    exchange_config['timeout'] = 25000\n",
        "\n",
        "                elif ex_id == 'okx':\n",
        "                    exchange_config['options']['createMarketBuyOrderRequiresPrice'] = False\n",
        "\n",
        "                elif ex_id == 'bybit':\n",
        "                    exchange_config['options']['recvWindow'] = 10000\n",
        "                    exchange_config['timeout'] = 60000\n",
        "\n",
        "                elif ex_id == 'huobi':\n",
        "                    exchange_config['verify'] = False\n",
        "                    exchange_config['timeout'] = 60000\n",
        "\n",
        "                elif ex_id == 'gateio':\n",
        "                    exchange_config['options']['createMarketBuyOrderRequiresPrice'] = False\n",
        "\n",
        "                # Ø³Ø§Ø®Øª instance ØµØ±Ø§ÙÛŒ\n",
        "                exchange = config['class'](exchange_config)\n",
        "\n",
        "                # ØªØ³Øª Ø§ØªØµØ§Ù„\n",
        "                logger.info(f\"   â³ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ markets...\")\n",
        "                markets = exchange.load_markets()\n",
        "\n",
        "                if markets and len(markets) > 0:\n",
        "                    self.exchanges[ex_id] = exchange\n",
        "\n",
        "                    # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø±\n",
        "                    spot_markets = [m for m in markets.values() if m.get('spot', False)]\n",
        "                    logger.info(f\"   âœ… {ex_id.upper()} Ù…ØªØµÙ„ Ø´Ø¯\")\n",
        "                    logger.info(f\"      ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ø¨Ø§Ø²Ø§Ø±Ù‡Ø§: {len(markets)}\")\n",
        "                    logger.info(f\"      ğŸ’° Ø¨Ø§Ø²Ø§Ø±Ù‡Ø§ÛŒ Spot: {len(spot_markets)}\")\n",
        "                    logger.info(f\"      âš¡ Rate Limit: {config['max_requests_per_minute']} req/min\")\n",
        "                    logger.info(f\"      ğŸ¯ Weight: {config['weight']}\")\n",
        "                else:\n",
        "                    raise Exception(\"No markets loaded\")\n",
        "\n",
        "            except ccxt.NetworkError as e:\n",
        "                self.failed_exchanges.append(ex_id)\n",
        "                logger.warning(f\"   âš ï¸ {ex_id.upper()}: Ù…Ø´Ú©Ù„ Ø´Ø¨Ú©Ù‡ - {str(e)[:100]}\")\n",
        "\n",
        "            except ccxt.ExchangeError as e:\n",
        "                self.failed_exchanges.append(ex_id)\n",
        "                logger.warning(f\"   âš ï¸ {ex_id.upper()}: Ø®Ø·Ø§ÛŒ ØµØ±Ø§ÙÛŒ - {str(e)[:100]}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                self.failed_exchanges.append(ex_id)\n",
        "                logger.error(f\"   âŒ {ex_id.upper()}: Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ - {str(e)[:100]}\")\n",
        "\n",
        "        # Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬\n",
        "        logger.info(\"\\n\" + \"=\" * 60)\n",
        "        logger.info(\"ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ø§ØªØµØ§Ù„Ø§Øª:\")\n",
        "        logger.info(\"=\" * 60)\n",
        "        logger.info(f\"âœ… Ù…ÙˆÙÙ‚: {len(self.exchanges)} ØµØ±Ø§ÙÛŒ\")\n",
        "        logger.info(f\"âŒ Ù†Ø§Ù…ÙˆÙÙ‚: {len(self.failed_exchanges)} ØµØ±Ø§ÙÛŒ\")\n",
        "\n",
        "        if self.exchanges:\n",
        "            logger.info(f\"\\nğŸ¯ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„ (Ø¨Ù‡ ØªØ±ØªÛŒØ¨ Ø§ÙˆÙ„ÙˆÛŒØª):\")\n",
        "            for ex_id in self.exchanges.keys():\n",
        "                weight = EXCHANGES_CONFIG[ex_id]['weight']\n",
        "                logger.info(f\"   â€¢ {ex_id.upper()} (ÙˆØ²Ù†: {weight})\")\n",
        "\n",
        "        if self.failed_exchanges:\n",
        "            logger.warning(f\"\\nâš ï¸ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ ØºÛŒØ±ÙØ¹Ø§Ù„:\")\n",
        "            for ex_id in self.failed_exchanges:\n",
        "                logger.warning(f\"   â€¢ {ex_id.upper()}\")\n",
        "\n",
        "        logger.info(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¯Ø§Ù‚Ù„ ØµØ±Ø§ÙÛŒ\n",
        "        if len(self.exchanges) < 2:\n",
        "            logger.error(\"âŒ Ù‡Ø´Ø¯Ø§Ø±: Ú©Ù…ØªØ± Ø§Ø² 2 ØµØ±Ø§ÙÛŒ Ù…ØªØµÙ„ Ø§Ø³Øª!\")\n",
        "            if len(self.exchanges) == 0:\n",
        "                raise Exception(\"âŒ Ø®Ø·Ø§ÛŒ Ø¨Ø­Ø±Ø§Ù†ÛŒ: Ù‡ÛŒÚ† ØµØ±Ø§ÙÛŒ Ù…ØªØµÙ„ Ù†Ø´Ø¯!\")\n",
        "\n",
        "        return self.exchanges\n",
        "\n",
        "    def fetch_ohlcv_with_cache(self, symbol: str, timeframe: str, limit: int = 500,\n",
        "                                force_fresh: bool = False, max_age_hours: float = 1) -> Optional[pd.DataFrame]:\n",
        "        \"\"\"Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ Ú©Ø´ Ùˆ Ø§ÙˆÙ„ÙˆÛŒØª KuCoin\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"ğŸ“¥ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… {timeframe}...\")\n",
        "\n",
        "            df = fetch_data(\n",
        "                symbol=symbol,\n",
        "                timeframe=timeframe,\n",
        "                limit=limit,\n",
        "                force_fresh=force_fresh,\n",
        "                max_age_hours=max_age_hours,\n",
        "                max_retries=3,\n",
        "                delay=5\n",
        "            )\n",
        "\n",
        "            if df is not None and len(df) > 0:\n",
        "                if validate_data(df):\n",
        "                    logger.info(f\"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± {symbol} Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯: {len(df)} Ú©Ù†Ø¯Ù„\")\n",
        "                    return df\n",
        "                else:\n",
        "                    logger.warning(f\"âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ {symbol} Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù†Ø´Ø¯ØŒ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯...\")\n",
        "                    df = fetch_data(\n",
        "                        symbol=symbol,\n",
        "                        timeframe=timeframe,\n",
        "                        limit=limit,\n",
        "                        force_fresh=True,\n",
        "                        max_age_hours=max_age_hours\n",
        "                    )\n",
        "                    if df is not None and validate_data(df):\n",
        "                        logger.info(f\"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¯Ø± ØªÙ„Ø§Ø´ Ø¯ÙˆÙ… Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯\")\n",
        "                        return df\n",
        "                    else:\n",
        "                        logger.error(f\"âŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯\")\n",
        "                        return None\n",
        "            else:\n",
        "                logger.warning(f\"âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø± {timeframe} Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ {symbol}/{timeframe}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def fetch_ohlcv(self, symbol: str, timeframe: str, limit: int = 500) -> Optional[pd.DataFrame]:\n",
        "        \"\"\"Ø¯Ø±ÛŒØ§ÙØª Ø³Ø§Ø¯Ù‡ Ø¯Ø§Ø¯Ù‡ OHLCV\"\"\"\n",
        "        return self.fetch_ohlcv_with_cache(symbol, timeframe, limit, force_fresh=False)\n",
        "\n",
        "def fetch_data(symbol, timeframe, limit=500, force_fresh=False, max_age_hours=1,\n",
        "               max_retries=3, delay=5, incremental=False):\n",
        "    \"\"\"Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ Ø§ÙˆÙ„ÙˆÛŒØª KuCoin Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡\"\"\"\n",
        "\n",
        "    cache_key = get_cache_key(\"fetch_data\", symbol, timeframe, limit)\n",
        "\n",
        "    # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø´\n",
        "    if not force_fresh and cache_key in memory_cache:\n",
        "        cache_age = time.time() - memory_cache_access_time.get(cache_key, 0)\n",
        "        if cache_age < max_age_hours * 3600:\n",
        "            memory_cache_access_time[cache_key] = time.time()\n",
        "            logger.info(f\"âœ… Ú©Ø´ Ø­Ø§ÙØ¸Ù‡: {symbol}/{timeframe} (Ø³Ù†: {cache_age/60:.1f} Ø¯Ù‚ÛŒÙ‚Ù‡)\")\n",
        "            return memory_cache[cache_key].copy()\n",
        "\n",
        "    # Ø§ÙˆÙ„ÙˆÛŒØª ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ - KuCoin Ø§ÙˆÙ„\n",
        "    exchange_priority = ['kucoin', 'okx', 'gateio', 'bitget', 'mexc', 'bybit', 'huobi']\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        for ex_id in exchange_priority:\n",
        "            if ex_id not in EXCHANGES_CONFIG:\n",
        "                continue\n",
        "\n",
        "            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ú©ÙˆÙ„Ø¯Ø§ÙˆÙ†\n",
        "            state = exchange_state.get(ex_id, {})\n",
        "            if state.get('in_cooldown', False):\n",
        "                if time.time() < state.get('cooldown_until', 0):\n",
        "                    continue\n",
        "                else:\n",
        "                    # Ø®Ø±ÙˆØ¬ Ø§Ø² Ú©ÙˆÙ„Ø¯Ø§ÙˆÙ†\n",
        "                    state['in_cooldown'] = False\n",
        "                    state['cooldown_until'] = 0\n",
        "\n",
        "            try:\n",
        "                config = EXCHANGES_CONFIG[ex_id]\n",
        "\n",
        "                # ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØµØ±Ø§ÙÛŒ\n",
        "                exchange_config = {\n",
        "                    'enableRateLimit': True,\n",
        "                    'timeout': 45000,\n",
        "                    'options': {'defaultType': 'spot'},\n",
        "                    'headers': {\n",
        "                        'User-Agent': 'Mozilla/5.0 (compatible; trading-bot/1.0)'\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø®Ø§Øµ Ù‡Ø± ØµØ±Ø§ÙÛŒ\n",
        "                if ex_id == 'kucoin':\n",
        "                    exchange_config['sandbox'] = False\n",
        "                    exchange_config['timeout'] = 30000\n",
        "\n",
        "                elif ex_id == 'okx':\n",
        "                    exchange_config['options']['createMarketBuyOrderRequiresPrice'] = False\n",
        "\n",
        "                elif ex_id == 'bybit':\n",
        "                    exchange_config['options']['recvWindow'] = 10000\n",
        "                    exchange_config['timeout'] = 60000\n",
        "\n",
        "                elif ex_id == 'huobi':\n",
        "                    exchange_config['verify'] = False  # Ø­Ù„ Ù…Ø´Ú©Ù„ SSL\n",
        "                    exchange_config['timeout'] = 60000\n",
        "\n",
        "                elif ex_id == 'gateio':\n",
        "                    exchange_config['options']['createMarketBuyOrderRequiresPrice'] = False\n",
        "\n",
        "                # Ø³Ø§Ø®Øª instance ØµØ±Ø§ÙÛŒ\n",
        "                exchange = config['class'](exchange_config)\n",
        "\n",
        "                # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ù…Ø§Ø¯\n",
        "                try:\n",
        "                    markets = exchange.load_markets()\n",
        "                    if symbol not in markets:\n",
        "                        logger.debug(f\"âŒ {symbol} Ø¯Ø± {ex_id} Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª\")\n",
        "                        continue\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ markets {ex_id}: {str(e)[:50]}\")\n",
        "                    continue\n",
        "\n",
        "                # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ OHLCV\n",
        "                logger.info(f\"ğŸ“¥ Ø¯Ø±Ø®ÙˆØ§Ø³Øª {symbol}/{timeframe} Ø§Ø² {ex_id}...\")\n",
        "                ohlcv = exchange.fetch_ohlcv(symbol, timeframe, limit=limit)\n",
        "\n",
        "                if not ohlcv or len(ohlcv) < 20:\n",
        "                    logger.warning(f\"âŒ Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ú©Ø§ÙÛŒ Ø§Ø² {ex_id}: {len(ohlcv) if ohlcv else 0} Ú©Ù†Ø¯Ù„\")\n",
        "                    continue\n",
        "\n",
        "                # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame\n",
        "                df = pd.DataFrame(\n",
        "                    ohlcv,\n",
        "                    columns=['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
        "                )\n",
        "                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "                df.set_index('timestamp', inplace=True)\n",
        "\n",
        "                # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø¯Ø§Ø¯Ù‡\n",
        "                if not validate_data(df):\n",
        "                    logger.warning(f\"âŒ Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø² {ex_id}\")\n",
        "                    continue\n",
        "\n",
        "                # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´\n",
        "                memory_cache[cache_key] = df\n",
        "                memory_cache_access_time[cache_key] = time.time()\n",
        "\n",
        "                # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ú©Ø´ Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²\n",
        "                if len(memory_cache) > BOT_SETTINGS.get('max_memory_cache_size', 300):\n",
        "                    clean_memory_cache()\n",
        "\n",
        "                # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø± Ù…ÙˆÙÙ‚ÛŒØª\n",
        "                with request_count_lock:\n",
        "                    if ex_id not in exchange_state:\n",
        "                        exchange_state[ex_id] = {\n",
        "                            'success_count': 0, 'fail_count': 0,\n",
        "                            'in_cooldown': False, 'cooldown_until': 0\n",
        "                        }\n",
        "                    exchange_state[ex_id]['success_count'] += 1\n",
        "\n",
        "                logger.info(f\"âœ… Ø¯Ø±ÛŒØ§ÙØª {symbol}/{timeframe}: {len(df)} Ú©Ù†Ø¯Ù„ Ø§Ø² {ex_id}\")\n",
        "                return df.copy()\n",
        "\n",
        "            except ccxt.RateLimitExceeded:\n",
        "                logger.warning(f\"â³ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® {ex_id} - ØªÙ„Ø§Ø´ {attempt+1}/{max_retries}\")\n",
        "                handle_rate_limit(ex_id)\n",
        "                continue  # Ø±ÙØªÙ† Ø¨Ù‡ ØµØ±Ø§ÙÛŒ Ø¨Ø¹Ø¯ÛŒ\n",
        "\n",
        "            except ccxt.ExchangeError as e:\n",
        "                error_msg = str(e).lower()\n",
        "                if \"does not have market symbol\" in error_msg:\n",
        "                    logger.error(f\"âŒ Ø®Ø·Ø§ÛŒ ØµØ±Ø§ÙÛŒ {ex_id}: {ex_id} does not have market symbol {symbol}\")\n",
        "                else:\n",
        "                    logger.error(f\"âŒ Ø®Ø·Ø§ÛŒ ØµØ±Ø§ÙÛŒ {ex_id}: {str(e)[:100]}\")\n",
        "\n",
        "                # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø± Ø´Ú©Ø³Øª\n",
        "                with request_count_lock:\n",
        "                    if ex_id not in exchange_state:\n",
        "                        exchange_state[ex_id] = {\n",
        "                            'success_count': 0, 'fail_count': 0,\n",
        "                            'in_cooldown': False, 'cooldown_until': 0\n",
        "                        }\n",
        "                    exchange_state[ex_id]['fail_count'] += 1\n",
        "                continue\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ {ex_id}: {str(e)[:100]}\")\n",
        "                logger.error(traceback.format_exc())\n",
        "\n",
        "                # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø± Ø´Ú©Ø³Øª\n",
        "                with request_count_lock:\n",
        "                    if ex_id not in exchange_state:\n",
        "                        exchange_state[ex_id] = {\n",
        "                            'success_count': 0, 'fail_count': 0,\n",
        "                            'in_cooldown': False, 'cooldown_until': 0\n",
        "                        }\n",
        "                    exchange_state[ex_id]['fail_count'] += 1\n",
        "                continue\n",
        "\n",
        "        # ØªØ§Ø®ÛŒØ± Ø¨ÛŒÙ† ØªÙ„Ø§Ø´â€ŒÙ‡Ø§\n",
        "        if attempt < max_retries - 1:\n",
        "            sleep_time = delay * (attempt + 1)\n",
        "            logger.info(f\"â³ ØªØ§Ø®ÛŒØ± {sleep_time} Ø«Ø§Ù†ÛŒÙ‡ Ù‚Ø¨Ù„ Ø§Ø² ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯...\")\n",
        "            time.sleep(sleep_time)\n",
        "\n",
        "    logger.error(f\"âŒ Ø¯Ø±ÛŒØ§ÙØª {symbol}/{timeframe} Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯ Ø¨Ø¹Ø¯ Ø§Ø² {max_retries} ØªÙ„Ø§Ø´\")\n",
        "    return None\n",
        "\n",
        "def save_to_disk_cache(key: str, data: Any):\n",
        "    try:\n",
        "        hash_key = hashlib.md5(key.encode()).hexdigest()\n",
        "        path = f\"{BASE_DIR}/cache/disk/{hash_key}.pkl\"\n",
        "\n",
        "        with open(path, 'wb') as f:\n",
        "            pickle.dump(data, f, protocol=4)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ø®Ø·Ø§ Ø°Ø®ÛŒØ±Ù‡ Ø¯ÛŒØ³Ú©: {e}\")\n",
        "        return False\n",
        "\n",
        "def load_from_disk_cache(key: str) -> Optional[Any]:\n",
        "    try:\n",
        "        hash_key = hashlib.md5(key.encode()).hexdigest()\n",
        "        path = f\"{BASE_DIR}/cache/disk/{hash_key}.pkl\"\n",
        "\n",
        "        if not os.path.exists(path):\n",
        "            return None\n",
        "\n",
        "        if time.time() - os.path.getmtime(path) > CACHE_MAX_AGE_HOURS * 3600:\n",
        "            os.remove(path)\n",
        "            return None\n",
        "\n",
        "        with open(path, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def cleanup_files():\n",
        "    global last_cleanup\n",
        "\n",
        "    if time.time() - last_cleanup < 3600:\n",
        "        return\n",
        "\n",
        "    logger.info(\"ğŸ—‘ï¸ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§...\")\n",
        "\n",
        "    charts_dir = f\"{BASE_DIR}/charts\"\n",
        "    if os.path.exists(charts_dir):\n",
        "        files = sorted(\n",
        "            [(f, os.path.getmtime(os.path.join(charts_dir, f)))\n",
        "             for f in os.listdir(charts_dir) if f.endswith('.png')],\n",
        "            key=lambda x: x[1], reverse=True\n",
        "        )\n",
        "        for f, _ in files[20:]:\n",
        "            try:\n",
        "                os.remove(os.path.join(charts_dir, f))\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    for cache_dir in [f\"{BASE_DIR}/cache/ohlcv\", f\"{BASE_DIR}/cache/disk\"]:\n",
        "        if os.path.exists(cache_dir):\n",
        "            for f in os.listdir(cache_dir):\n",
        "                path = os.path.join(cache_dir, f)\n",
        "                try:\n",
        "                    if time.time() - os.path.getmtime(path) > 12 * 3600:\n",
        "                        os.remove(path)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "    last_cleanup = time.time()\n",
        "    logger.info(\"âœ… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø´Ø¯\")\n",
        "\n",
        "cleanup_drive_files = cleanup_files\n",
        "\n",
        "def monitor_resources() -> Dict:\n",
        "    try:\n",
        "        memory = psutil.virtual_memory()\n",
        "\n",
        "        status = {\n",
        "            'memory_percent': memory.percent,\n",
        "            'memory_available_gb': memory.available / (1024**3),\n",
        "            'cache_items': len(memory_cache),\n",
        "        }\n",
        "\n",
        "        if memory.percent > 80:\n",
        "            logger.warning(f\"ğŸš¨ Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§Ù„Ø§: {memory.percent:.1f}%\")\n",
        "            clean_memory_cache(force_cleanup=True)\n",
        "        elif memory.percent > 60:\n",
        "            clean_memory_cache(force_cleanup=True)\n",
        "\n",
        "        return status\n",
        "    except:\n",
        "        return {}\n",
        "\n",
        "def get_best_exchange(symbol: str, operation: str = \"ohlcv\") -> str:\n",
        "    \"\"\"Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† ØµØ±Ø§ÙÛŒ Ø¨Ø§ Ø§ÙˆÙ„ÙˆÛŒØª KuCoin\"\"\"\n",
        "\n",
        "    # Ø§ÙˆÙ„ÙˆÛŒØª Ø«Ø§Ø¨Øª ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ - KuCoin Ø¯Ø± Ø§ÙˆÙ„ÙˆÛŒØª Ø§ÙˆÙ„\n",
        "    priority_order = ['kucoin', 'okx', 'gateio', 'bitget', 'mexc', 'bybit', 'huobi']\n",
        "\n",
        "    for ex_id in priority_order:\n",
        "        if ex_id not in EXCHANGES_CONFIG:\n",
        "            continue\n",
        "\n",
        "        config = EXCHANGES_CONFIG[ex_id]\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§\n",
        "        if operation not in config.get('features', []):\n",
        "            continue\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ú©ÙˆÙ„Ø¯Ø§ÙˆÙ†\n",
        "        state = exchange_state.get(ex_id, {})\n",
        "        if state.get('in_cooldown', False):\n",
        "            if time.time() < state.get('cooldown_until', 0):\n",
        "                continue\n",
        "            else:\n",
        "                # Ø®Ø±ÙˆØ¬ Ø§Ø² Ú©ÙˆÙ„Ø¯Ø§ÙˆÙ†\n",
        "                state['in_cooldown'] = False\n",
        "                state['cooldown_until'] = 0\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ù‚Ø§Ø¨Ù„ÛŒØª Ø§Ø¹ØªÙ…Ø§Ø¯\n",
        "        if not config.get('reliable', True):\n",
        "            # Ø¨Ø±Ø§ÛŒ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ ØºÛŒØ±Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªÙ…Ø§Ø¯ØŒ Ø¨Ø±Ø±Ø³ÛŒ Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª\n",
        "            total_requests = state.get('success_count', 0) + state.get('fail_count', 0)\n",
        "            if total_requests > 10:  # Ø§Ú¯Ø± Ø­Ø¯Ø§Ù‚Ù„ 10 Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø§Ø´ØªÙ‡\n",
        "                success_rate = state.get('success_count', 0) / total_requests\n",
        "                if success_rate < 0.5:  # Ø§Ú¯Ø± Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª Ú©Ù…ØªØ± Ø§Ø² 50%\n",
        "                    continue\n",
        "\n",
        "        return ex_id\n",
        "\n",
        "    # Ø§Ú¯Ø± Ù‡ÛŒÚ† ØµØ±Ø§ÙÛŒ Ù…Ù†Ø§Ø³Ø¨ Ù†Ø¨ÙˆØ¯ØŒ KuCoin Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†\n",
        "    return 'kucoin'\n",
        "\n",
        "def handle_rate_limit(exchange_id: str):\n",
        "    \"\"\"Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø®\"\"\"\n",
        "    if exchange_id not in exchange_state:\n",
        "        return\n",
        "\n",
        "    config = EXCHANGES_CONFIG.get(exchange_id, {})\n",
        "    cooldown_duration = config.get('cooldown', 60)\n",
        "\n",
        "    # Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯Ù† ØµØ±Ø§ÙÛŒ Ø¯Ø± Ú©ÙˆÙ„Ø¯Ø§ÙˆÙ†\n",
        "    exchange_state[exchange_id]['in_cooldown'] = True\n",
        "    exchange_state[exchange_id]['cooldown_until'] = time.time() + cooldown_duration\n",
        "\n",
        "    logger.warning(f\"â¸ï¸ {exchange_id} Ø¯Ø± Ú©ÙˆÙ„Ø¯Ø§ÙˆÙ† Ø¨Ø±Ø§ÛŒ {cooldown_duration} Ø«Ø§Ù†ÛŒÙ‡\")\n",
        "\n",
        "\n",
        "# ==================== Ø¨Ø®Ø´ 8: Ú©Ù„Ø§Ø³ Ø§ØµÙ„ÛŒ ====================\n",
        "class SmartMoneyWhaleHunter:\n",
        "\n",
        "    def __init__(self):\n",
        "        logger.info(\"ğŸš€ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ SmartMoneyWhaleHunter...\")\n",
        "\n",
        "        self.exchanges = self._init_exchanges()\n",
        "\n",
        "        self.swing_length = 50\n",
        "        self.internal_length = 10\n",
        "        self.ob_atr_period = 14\n",
        "        self.ob_atr_multiplier = 0.5\n",
        "        self.fvg_threshold = 0.001\n",
        "\n",
        "        self.whale_volume_threshold = 3.0\n",
        "        self.whale_price_impact = 0.005\n",
        "\n",
        "        self.liquidity_lookback = 100\n",
        "\n",
        "        logger.info(\"âœ… Ø³ÛŒØ³ØªÙ… Ø¢Ù…Ø§Ø¯Ù‡\")\n",
        "\n",
        "    def _init_exchanges(self) -> Dict:\n",
        "        \"\"\"Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡\"\"\"\n",
        "        exchanges = {}\n",
        "        failed_exchanges = []\n",
        "\n",
        "        logger.info(\"=\" * 60)\n",
        "        logger.info(\"ğŸ”Œ Ø´Ø±ÙˆØ¹ Ø§ØªØµØ§Ù„ Ø¨Ù‡ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§...\")\n",
        "        logger.info(\"=\" * 60)\n",
        "\n",
        "        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ weight (Ø§ÙˆÙ„ÙˆÛŒØª)\n",
        "        sorted_exchanges = sorted(\n",
        "            EXCHANGES_CONFIG.items(),\n",
        "            key=lambda x: x[1]['weight'],\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        for ex_id, config in sorted_exchanges:\n",
        "            try:\n",
        "                logger.info(f\"\\nğŸ“¡ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ {ex_id.upper()}...\")\n",
        "\n",
        "                # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø§ÛŒÙ‡\n",
        "                exchange_config = {\n",
        "                    'enableRateLimit': True,\n",
        "                    'timeout': 30000,  # 30 Ø«Ø§Ù†ÛŒÙ‡\n",
        "                    'options': {\n",
        "                        'defaultType': 'spot',\n",
        "                        'adjustForTimeDifference': True,  # ØªÙ†Ø¸ÛŒÙ… Ø®ÙˆØ¯Ú©Ø§Ø± timezone\n",
        "                    },\n",
        "                    'headers': {\n",
        "                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø®Ø§Øµ Ù‡Ø± ØµØ±Ø§ÙÛŒ\n",
        "                if ex_id == 'kucoin':\n",
        "                    exchange_config['options']['versions'] = {\n",
        "                        'public': {'GET': 'v1'},\n",
        "                        'private': {'GET': 'v1', 'POST': 'v1'},\n",
        "                    }\n",
        "\n",
        "                elif ex_id == 'bybit':\n",
        "                    exchange_config['options']['recvWindow'] = 10000\n",
        "\n",
        "                elif ex_id == 'kraken':\n",
        "                    exchange_config['timeout'] = 60000  # Kraken Ù†ÛŒØ§Ø² Ø¨Ù‡ timeout Ø¨ÛŒØ´ØªØ±\n",
        "\n",
        "                elif ex_id == 'gateio':\n",
        "                    exchange_config['options']['createMarketBuyOrderRequiresPrice'] = False\n",
        "\n",
        "                # Ø³Ø§Ø®Øª instance ØµØ±Ø§ÙÛŒ\n",
        "                exchange = config['class'](exchange_config)\n",
        "\n",
        "                # ØªØ³Øª Ø§ØªØµØ§Ù„ Ø¨Ø§ load_markets\n",
        "                logger.info(f\"   â³ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ markets...\")\n",
        "                markets = exchange.load_markets()\n",
        "\n",
        "                if markets and len(markets) > 0:\n",
        "                    exchanges[ex_id] = exchange\n",
        "\n",
        "                    # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø±\n",
        "                    spot_markets = [m for m in markets.values() if m.get('spot', False)]\n",
        "                    logger.info(f\"   âœ… {ex_id.upper()} Ù…ØªØµÙ„ Ø´Ø¯\")\n",
        "                    logger.info(f\"      ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ø¨Ø§Ø²Ø§Ø±Ù‡Ø§: {len(markets)}\")\n",
        "                    logger.info(f\"      ğŸ’° Ø¨Ø§Ø²Ø§Ø±Ù‡Ø§ÛŒ Spot: {len(spot_markets)}\")\n",
        "                    logger.info(f\"      âš¡ Rate Limit: {config['max_requests_per_minute']} req/min\")\n",
        "                    logger.info(f\"      ğŸ¯ Weight: {config['weight']}\")\n",
        "\n",
        "                else:\n",
        "                    raise Exception(\"No markets loaded\")\n",
        "\n",
        "            except ccxt.NetworkError as e:\n",
        "                failed_exchanges.append(ex_id)\n",
        "                logger.warning(f\"   âš ï¸ {ex_id.upper()}: Ù…Ø´Ú©Ù„ Ø´Ø¨Ú©Ù‡ - {str(e)[:100]}\")\n",
        "\n",
        "            except ccxt.ExchangeError as e:\n",
        "                failed_exchanges.append(ex_id)\n",
        "                logger.warning(f\"   âš ï¸ {ex_id.upper()}: Ø®Ø·Ø§ÛŒ ØµØ±Ø§ÙÛŒ - {str(e)[:100]}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                failed_exchanges.append(ex_id)\n",
        "                logger.error(f\"   âŒ {ex_id.upper()}: Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ - {str(e)[:100]}\")\n",
        "                if 'restricted location' in str(e).lower() or '451' in str(e):\n",
        "                    logger.error(f\"      ğŸš« Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯!\")\n",
        "\n",
        "        # Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬\n",
        "        logger.info(\"\\n\" + \"=\" * 60)\n",
        "        logger.info(\"ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ø§ØªØµØ§Ù„Ø§Øª:\")\n",
        "        logger.info(\"=\" * 60)\n",
        "        logger.info(f\"âœ… Ù…ÙˆÙÙ‚: {len(exchanges)} ØµØ±Ø§ÙÛŒ\")\n",
        "        logger.info(f\"âŒ Ù†Ø§Ù…ÙˆÙÙ‚: {len(failed_exchanges)} ØµØ±Ø§ÙÛŒ\")\n",
        "\n",
        "        if exchanges:\n",
        "            logger.info(f\"\\nğŸ¯ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„ (Ø¨Ù‡ ØªØ±ØªÛŒØ¨ Ø§ÙˆÙ„ÙˆÛŒØª):\")\n",
        "            for ex_id in exchanges.keys():\n",
        "                weight = EXCHANGES_CONFIG[ex_id]['weight']\n",
        "                logger.info(f\"   â€¢ {ex_id.upper()} (ÙˆØ²Ù†: {weight})\")\n",
        "\n",
        "        if failed_exchanges:\n",
        "            logger.warning(f\"\\nâš ï¸ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ ØºÛŒØ±ÙØ¹Ø§Ù„:\")\n",
        "            for ex_id in failed_exchanges:\n",
        "                logger.warning(f\"   â€¢ {ex_id.upper()}\")\n",
        "\n",
        "        logger.info(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¯Ø§Ù‚Ù„ ØµØ±Ø§ÙÛŒ\n",
        "        if len(exchanges) < 2:\n",
        "            logger.error(\"âŒ Ù‡Ø´Ø¯Ø§Ø±: Ú©Ù…ØªØ± Ø§Ø² 2 ØµØ±Ø§ÙÛŒ Ù…ØªØµÙ„ Ø§Ø³Øª!\")\n",
        "            if len(exchanges) == 0:\n",
        "                raise Exception(\"âŒ Ø®Ø·Ø§ÛŒ Ø¨Ø­Ø±Ø§Ù†ÛŒ: Ù‡ÛŒÚ† ØµØ±Ø§ÙÛŒ Ù…ØªØµÙ„ Ù†Ø´Ø¯!\")\n",
        "\n",
        "        return exchanges\n",
        "\n",
        "\n",
        "    def fetch_ohlcv_with_cache(self, symbol: str, timeframe: str, limit: int = 500,\n",
        "                                force_fresh: bool = False, max_age_hours: float = 1) -> Optional[pd.DataFrame]:\n",
        "        try:\n",
        "            logger.info(f\"ğŸ“¥ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… {timeframe}...\")\n",
        "\n",
        "            df = fetch_data(\n",
        "                symbol=symbol,\n",
        "                timeframe=timeframe,\n",
        "                limit=limit,\n",
        "                force_fresh=force_fresh,\n",
        "                max_age_hours=max_age_hours,\n",
        "                max_retries=5,\n",
        "                delay=2\n",
        "            )\n",
        "\n",
        "            if df is not None and len(df) > 0:\n",
        "                if validate_data(df):\n",
        "                    logger.info(f\"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± {symbol} Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯: {len(df)} Ú©Ù†Ø¯Ù„\")\n",
        "                    return df\n",
        "                else:\n",
        "                    logger.warning(f\"âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ {symbol} Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù†Ø´Ø¯ØŒ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯...\")\n",
        "                    df = fetch_data(\n",
        "                        symbol=symbol,\n",
        "                        timeframe=timeframe,\n",
        "                        limit=limit,\n",
        "                        force_fresh=True,\n",
        "                        max_age_hours=max_age_hours\n",
        "                    )\n",
        "                    if df is not None and validate_data(df):\n",
        "                        logger.info(f\"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¯Ø± ØªÙ„Ø§Ø´ Ø¯ÙˆÙ… Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯\")\n",
        "                        return df\n",
        "                    else:\n",
        "                        logger.error(f\"âŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯\")\n",
        "                        return None\n",
        "            else:\n",
        "                logger.warning(f\"âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø± {timeframe} Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ {symbol}/{timeframe}: {e}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return None\n",
        "\n",
        "    def fetch_ohlcv(self, symbol: str, timeframe: str, limit: int = 500) -> Optional[pd.DataFrame]:\n",
        "        return self.fetch_ohlcv_with_cache(symbol, timeframe, limit, force_fresh=False)\n",
        "\n",
        "\n",
        "    def fetch_market_dominance(self) -> Dict:\n",
        "        \"\"\"Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø± Ø¨Ø§ USDT Dominance Ùˆ Market Phase Detection\"\"\"\n",
        "        cache_key = get_cache_key('dominance')\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø´\n",
        "        if cache_key in memory_cache:\n",
        "            if time.time() - memory_cache_access_time.get(cache_key, 0) < 600:  # 10 Ø¯Ù‚ÛŒÙ‚Ù‡\n",
        "                return memory_cache[cache_key]\n",
        "\n",
        "        dominance = {\n",
        "            'btc_dominance': 0,\n",
        "            'btc_trend': 'neutral',\n",
        "            'usdt_dominance': 0,\n",
        "            'usdt_trend': 'neutral',\n",
        "            'total_mcap': 0,\n",
        "            'market_phase': 'neutral',\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Ø¯Ø±ÛŒØ§ÙØª BTC Dominance Ø§Ø² CoinGecko\n",
        "            resp = requests.get('https://api.coingecko.com/api/v3/global', timeout=10)\n",
        "\n",
        "            if resp.status_code == 200:\n",
        "                data = resp.json()['data']\n",
        "                dominance['btc_dominance'] = data['market_cap_percentage'].get('btc', 0)\n",
        "                dominance['total_mcap'] = data.get('total_market_cap', {}).get('usd', 0)\n",
        "                logger.info(f\"BTC Dominance: {dominance['btc_dominance']:.2f}%\")\n",
        "\n",
        "            # ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯ BTC.D Ø§Ø² Ù‚ÛŒÙ…Øª BTC\n",
        "            btc_d_data = self.fetch_ohlcv_with_cache('BTC/USDT', '1h', limit=50)\n",
        "            if btc_d_data is not None:\n",
        "                btc_d_data['sma'] = btc_d_data['close'].rolling(20).mean()\n",
        "                if btc_d_data['close'].iloc[-1] > btc_d_data['sma'].iloc[-1]:\n",
        "                    dominance['btc_trend'] = 'rising'\n",
        "                else:\n",
        "                    dominance['btc_trend'] = 'falling'\n",
        "\n",
        "            # Ù…Ø­Ø§Ø³Ø¨Ù‡ USDT Dominance Ø§Ø² Volume\n",
        "            try:\n",
        "                if 'binance' in self.exchanges:\n",
        "                    exchange = self.exchanges['binance']\n",
        "                    tickers = exchange.fetch_tickers()\n",
        "\n",
        "                    usdt_volume = 0\n",
        "                    total_volume = 0\n",
        "\n",
        "                    for symbol, ticker in tickers.items():\n",
        "                        quote_vol = ticker.get('quoteVolume', 0)\n",
        "                        if quote_vol and quote_vol > 0:\n",
        "                            total_volume += quote_vol\n",
        "                            if 'USDT' in symbol:\n",
        "                                usdt_volume += quote_vol\n",
        "\n",
        "                    if total_volume > 0:\n",
        "                        dominance['usdt_dominance'] = (usdt_volume / total_volume) * 100\n",
        "                    else:\n",
        "                        dominance['usdt_dominance'] = 5.0\n",
        "\n",
        "                    # ØªØ¹ÛŒÛŒÙ† Ø±ÙˆÙ†Ø¯ USDT\n",
        "                    if dominance['usdt_dominance'] > 6:\n",
        "                        dominance['usdt_trend'] = 'rising'  # Risk-Off - Ø®Ø±ÙˆØ¬ Ù¾ÙˆÙ„\n",
        "                        logger.info(\"USDT.D Ø¨Ø§Ù„Ø§ - Ø­Ø§Ù„Øª Risk-Off\")\n",
        "                    else:\n",
        "                        dominance['usdt_trend'] = 'falling'  # Risk-On - ÙˆØ±ÙˆØ¯ Ù¾ÙˆÙ„\n",
        "\n",
        "                    logger.info(f\"USDT Dominance: {dominance['usdt_dominance']:.2f}%\")\n",
        "                else:\n",
        "                    dominance['usdt_dominance'] = 5.0\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ USDT.D: {e}\")\n",
        "                dominance['usdt_dominance'] = 5.0\n",
        "\n",
        "            # ØªØ´Ø®ÛŒØµ ÙØ§Ø² Ø¨Ø§Ø²Ø§Ø± (Market Phase Detection)\n",
        "            btc_d = dominance['btc_dominance']\n",
        "            btc_trend = dominance['btc_trend']\n",
        "            usdt_d = dominance['usdt_dominance']\n",
        "\n",
        "            if btc_trend == 'rising' and btc_d < 45:\n",
        "                dominance['market_phase'] = 'altseason'\n",
        "                logger.info(\"ğŸŒŸ ÙØ§Ø² Ø¨Ø§Ø²Ø§Ø±: Altseason\")\n",
        "\n",
        "            elif btc_trend == 'falling' and usdt_d > 6:\n",
        "                dominance['market_phase'] = 'bear_market'\n",
        "                logger.info(\"ğŸ» ÙØ§Ø² Ø¨Ø§Ø²Ø§Ø±: Bear Market\")\n",
        "\n",
        "            elif btc_d > 55:\n",
        "                dominance['market_phase'] = 'btc_accumulation'\n",
        "                logger.info(\"ğŸŸ  ÙØ§Ø² Ø¨Ø§Ø²Ø§Ø±: BTC Accumulation\")\n",
        "\n",
        "            else:\n",
        "                dominance['market_phase'] = 'neutral'\n",
        "                logger.info(\"â– ÙØ§Ø² Ø¨Ø§Ø²Ø§Ø±: Neutral\")\n",
        "\n",
        "            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´\n",
        "            memory_cache[cache_key] = dominance\n",
        "            memory_cache_access_time[cache_key] = time.time()\n",
        "\n",
        "            logger.info(f\"Market Context: BTC.D={btc_d:.2f}% ({btc_trend}), USDT.D={usdt_d:.2f}%, Phase={dominance['market_phase']}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Dominance: {e}\")\n",
        "\n",
        "        return dominance\n",
        "\n",
        "    def detect_swing_points(self, df: pd.DataFrame, length: int) -> Tuple[pd.Series, pd.Series]:\n",
        "        \"\"\"ØªØ´Ø®ÛŒØµ Swing Points\"\"\"\n",
        "        highs = pd.Series(index=df.index, dtype=float)\n",
        "        lows = pd.Series(index=df.index, dtype=float)\n",
        "\n",
        "        for i in range(length, len(df) - length):\n",
        "            if df['high'].iloc[i] == df['high'].iloc[i-length:i+length+1].max():\n",
        "                highs.iloc[i] = df['high'].iloc[i]\n",
        "\n",
        "            if df['low'].iloc[i] == df['low'].iloc[i-length:i+length+1].min():\n",
        "                lows.iloc[i] = df['low'].iloc[i]\n",
        "\n",
        "        return highs.dropna(), lows.dropna()\n",
        "\n",
        "    def detect_market_structure(self, df: pd.DataFrame, tf: str) -> List[MarketStructure]:\n",
        "        \"\"\"ØªØ´Ø®ÛŒØµ BOS & CHoCH\"\"\"\n",
        "        structures = []\n",
        "\n",
        "        length = self.swing_length if tf in ['1h', '4h'] else self.internal_length\n",
        "        swing_highs, swing_lows = self.detect_swing_points(df, length)\n",
        "\n",
        "        if len(swing_highs) < 2 or len(swing_lows) < 2:\n",
        "            return structures\n",
        "\n",
        "        all_swings = []\n",
        "        for idx in swing_highs.index:\n",
        "            all_swings.append(('high', idx, swing_highs[idx]))\n",
        "        for idx in swing_lows.index:\n",
        "            all_swings.append(('low', idx, swing_lows[idx]))\n",
        "\n",
        "        all_swings.sort(key=lambda x: x[1])\n",
        "\n",
        "        last_high = None\n",
        "        last_low = None\n",
        "        trend = None\n",
        "\n",
        "        for swing_type, swing_time, swing_price in all_swings:\n",
        "            if swing_type == 'high':\n",
        "                if last_high is not None:\n",
        "                    if swing_price > last_high:\n",
        "                        structure_type = 'CHoCH' if trend == 'bearish' else 'BOS'\n",
        "\n",
        "                        structures.append(MarketStructure(\n",
        "                            type=structure_type,\n",
        "                            direction='bullish',\n",
        "                            price=last_high,\n",
        "                            time=int(swing_time.timestamp() * 1000),\n",
        "                            strength=abs(swing_price - last_high) / last_high * 100\n",
        "                        ))\n",
        "\n",
        "                        trend = 'bullish'\n",
        "\n",
        "                last_high = swing_price\n",
        "\n",
        "            else:  # low\n",
        "                if last_low is not None:\n",
        "                    if swing_price < last_low:\n",
        "                        structure_type = 'CHoCH' if trend == 'bullish' else 'BOS'\n",
        "\n",
        "                        structures.append(MarketStructure(\n",
        "                            type=structure_type,\n",
        "                            direction='bearish',\n",
        "                            price=last_low,\n",
        "                            time=int(swing_time.timestamp() * 1000),\n",
        "                            strength=abs(swing_price - last_low) / last_low * 100\n",
        "                        ))\n",
        "\n",
        "                        trend = 'bearish'\n",
        "\n",
        "                last_low = swing_price\n",
        "\n",
        "        logger.info(f\"Market Structure: {len(structures)} Ø³Ø§Ø®ØªØ§Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯\")\n",
        "        return structures\n",
        "\n",
        "    def detect_order_blocks(self, df: pd.DataFrame, structures: List[MarketStructure]) -> List[OrderBlock]:\n",
        "        \"\"\"ØªØ´Ø®ÛŒØµ Order Blocks Ø¨Ø§ ÙÛŒÙ„ØªØ± ATR\"\"\"\n",
        "        obs = []\n",
        "\n",
        "        df['atr'] = ta.volatility.average_true_range(\n",
        "            df['high'], df['low'], df['close'], window=self.ob_atr_period\n",
        "        )\n",
        "\n",
        "        for structure in structures[-10:]:\n",
        "            st_time = pd.to_datetime(structure.time, unit='ms')\n",
        "\n",
        "            pre_break = df[df.index < st_time].tail(20)\n",
        "            if len(pre_break) == 0:\n",
        "                continue\n",
        "\n",
        "            if structure.direction == 'bullish':\n",
        "                bearish = pre_break[pre_break['close'] < pre_break['open']]\n",
        "\n",
        "                if len(bearish) > 0:\n",
        "                    ob = bearish.iloc[-1]\n",
        "                    candle_range = ob['high'] - ob['low']\n",
        "\n",
        "                    if candle_range > df['atr'].iloc[-1] * self.ob_atr_multiplier:\n",
        "                        vol_strength = (ob['volume'] / df['volume'].mean()) * 100\n",
        "                        strength = min(100, (vol_strength + structure.strength) / 2)\n",
        "\n",
        "                        obs.append(OrderBlock(\n",
        "                            high=ob['high'],\n",
        "                            low=ob['low'],\n",
        "                            time=int(ob.name.timestamp() * 1000),\n",
        "                            bias='bullish',\n",
        "                            strength=strength,\n",
        "                            volume=ob['volume']\n",
        "                        ))\n",
        "\n",
        "            else:  # bearish\n",
        "                bullish = pre_break[pre_break['close'] > pre_break['open']]\n",
        "\n",
        "                if len(bullish) > 0:\n",
        "                    ob = bullish.iloc[-1]\n",
        "                    candle_range = ob['high'] - ob['low']\n",
        "\n",
        "                    if candle_range > df['atr'].iloc[-1] * self.ob_atr_multiplier:\n",
        "                        vol_strength = (ob['volume'] / df['volume'].mean()) * 100\n",
        "                        strength = min(100, (vol_strength + structure.strength) / 2)\n",
        "\n",
        "                        obs.append(OrderBlock(\n",
        "                            high=ob['high'],\n",
        "                            low=ob['low'],\n",
        "                            time=int(ob.name.timestamp() * 1000),\n",
        "                            bias='bearish',\n",
        "                            strength=strength,\n",
        "                            volume=ob['volume']\n",
        "                        ))\n",
        "\n",
        "        obs.sort(key=lambda x: x.strength, reverse=True)\n",
        "\n",
        "        logger.info(f\"Order Blocks: {len(obs)} OB ÛŒØ§ÙØª Ø´Ø¯\")\n",
        "        return obs[:5]\n",
        "\n",
        "    def detect_fvg(self, df: pd.DataFrame) -> List[FairValueGap]:\n",
        "        \"\"\"ØªØ´Ø®ÛŒØµ Fair Value Gaps\"\"\"\n",
        "        fvgs = []\n",
        "\n",
        "        for i in range(2, len(df)):\n",
        "            c1 = df.iloc[i-2]\n",
        "            c2 = df.iloc[i-1]\n",
        "            c3 = df.iloc[i]\n",
        "\n",
        "            # Bullish FVG\n",
        "            if c3['low'] > c1['high']:\n",
        "                gap = c3['low'] - c1['high']\n",
        "\n",
        "                if gap / c1['high'] > self.fvg_threshold:\n",
        "                    fvgs.append(FairValueGap(\n",
        "                        top=c3['low'],\n",
        "                        bottom=c1['high'],\n",
        "                        time=int(c2.name.timestamp() * 1000),\n",
        "                        bias='bullish',\n",
        "                        size=gap\n",
        "                    ))\n",
        "\n",
        "            # Bearish FVG\n",
        "            elif c3['high'] < c1['low']:\n",
        "                gap = c1['low'] - c3['high']\n",
        "\n",
        "                if gap / c1['low'] > self.fvg_threshold:\n",
        "                    fvgs.append(FairValueGap(\n",
        "                        top=c1['low'],\n",
        "                        bottom=c3['high'],\n",
        "                        time=int(c2.name.timestamp() * 1000),\n",
        "                        bias='bearish',\n",
        "                        size=gap\n",
        "                    ))\n",
        "\n",
        "        logger.info(f\"FVG: {len(fvgs)} Ø´Ú©Ø§Ù ÛŒØ§ÙØª Ø´Ø¯\")\n",
        "        return fvgs[-10:]\n",
        "\n",
        "    def calculate_zones(self, df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Ù…Ø­Ø§Ø³Ø¨Ù‡ Premium/Discount Zones\"\"\"\n",
        "        swing_highs, swing_lows = self.detect_swing_points(df, self.swing_length)\n",
        "\n",
        "        if len(swing_highs) == 0 or len(swing_lows) == 0:\n",
        "            return {}\n",
        "\n",
        "        high = swing_highs.iloc[-1]\n",
        "        low = swing_lows.iloc[-1]\n",
        "        diff = high - low\n",
        "\n",
        "        zones = {\n",
        "            'premium': {'top': high, 'bottom': high - diff * 0.382},\n",
        "            'equilibrium': {'top': low + diff * 0.618, 'bottom': low + diff * 0.382},\n",
        "            'discount': {'top': low + diff * 0.382, 'bottom': low},\n",
        "            'range_high': high,\n",
        "            'range_low': low,\n",
        "        }\n",
        "\n",
        "        current = df['close'].iloc[-1]\n",
        "\n",
        "        if current >= zones['premium']['bottom']:\n",
        "            zones['current_zone'] = 'premium'\n",
        "        elif current <= zones['discount']['top']:\n",
        "            zones['current_zone'] = 'discount'\n",
        "        else:\n",
        "            zones['current_zone'] = 'equilibrium'\n",
        "\n",
        "        return zones\n",
        "\n",
        "    def detect_liquidity_zones(self, df: pd.DataFrame) -> List[LiquidityZone]:\n",
        "        \"\"\"ØªØ´Ø®ÛŒØµ Ù†ÙˆØ§Ø­ÛŒ Ù†Ù‚Ø¯ÛŒÙ†Ú¯ÛŒ\"\"\"\n",
        "        zones = []\n",
        "\n",
        "        swing_highs, swing_lows = self.detect_swing_points(df, 20)\n",
        "\n",
        "        # Equal Highs\n",
        "        highs_list = swing_highs.tolist()\n",
        "        for i in range(len(highs_list) - 1):\n",
        "            if abs(highs_list[i] - highs_list[i+1]) / highs_list[i] < 0.002:\n",
        "                zones.append(LiquidityZone(\n",
        "                    price=highs_list[i],\n",
        "                    type='sell',\n",
        "                    strength=70,\n",
        "                    time=int(swing_highs.index[i].timestamp() * 1000)\n",
        "                ))\n",
        "\n",
        "        # Equal Lows\n",
        "        lows_list = swing_lows.tolist()\n",
        "        for i in range(len(lows_list) - 1):\n",
        "            if abs(lows_list[i] - lows_list[i+1]) / lows_list[i] < 0.002:\n",
        "                zones.append(LiquidityZone(\n",
        "                    price=lows_list[i],\n",
        "                    type='buy',\n",
        "                    strength=70,\n",
        "                    time=int(swing_lows.index[i].timestamp() * 1000)\n",
        "                ))\n",
        "\n",
        "        logger.info(f\"Liquidity: {len(zones)} Ù†Ø§Ø­ÛŒÙ‡ Ù†Ù‚Ø¯ÛŒÙ†Ú¯ÛŒ\")\n",
        "        return zones\n",
        "\n",
        "    def detect_whale_activity(self, df: pd.DataFrame) -> List[WhaleActivity]:\n",
        "        \"\"\"ØªØ´Ø®ÛŒØµ ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§\"\"\"\n",
        "        activities = []\n",
        "\n",
        "        df['vol_ma'] = df['volume'].rolling(20).mean()\n",
        "        df['vol_ratio'] = df['volume'] / df['vol_ma']\n",
        "        df['price_change'] = df['close'].pct_change().abs()\n",
        "\n",
        "        whales = df[\n",
        "            (df['vol_ratio'] > self.whale_volume_threshold) &\n",
        "            (df['price_change'] > self.whale_price_impact)\n",
        "        ].tail(20)\n",
        "\n",
        "        for idx, candle in whales.iterrows():\n",
        "            activity_type = 'accumulation' if candle['close'] > candle['open'] else 'distribution'\n",
        "\n",
        "            vol_str = min(100, (candle['vol_ratio'] / self.whale_volume_threshold) * 50)\n",
        "            price_str = min(100, (candle['price_change'] / self.whale_price_impact) * 50)\n",
        "            strength = (vol_str + price_str) / 2\n",
        "\n",
        "            activities.append(WhaleActivity(\n",
        "                timestamp=int(idx.timestamp() * 1000),\n",
        "                volume=candle['volume'],\n",
        "                price=candle['close'],\n",
        "                type=activity_type,\n",
        "                strength=strength,\n",
        "                impact=candle['price_change'] * 100\n",
        "            ))\n",
        "\n",
        "        logger.info(f\"Whale Activity: {len(activities)} ÙØ¹Ø§Ù„ÛŒØª Ù†Ù‡Ù†Ú¯\")\n",
        "        return activities\n",
        "\n",
        "    def generate_signal(\n",
        "        self, symbol: str, tf: str, df: pd.DataFrame,\n",
        "        structures: List[MarketStructure],\n",
        "        obs: List[OrderBlock],\n",
        "        fvgs: List[FairValueGap],\n",
        "        zones: Dict,\n",
        "        whales: List[WhaleActivity],\n",
        "        liquidity: List[LiquidityZone],\n",
        "        market: Dict\n",
        "    ) -> Optional[TradingSignal]:\n",
        "        \"\"\"\n",
        "        ØªÙˆÙ„ÛŒØ¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ø¨Ø§ Ù…Ù†Ø·Ù‚ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡\n",
        "        Ø´Ø§Ù…Ù„: Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ú©Ø§Ù…Ù„ØŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø±ÛŒØ³Ú©ØŒ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø±\n",
        "        \"\"\"\n",
        "\n",
        "        current_price = df['close'].iloc[-1]\n",
        "        atr = df['atr'].iloc[-1] if 'atr' in df.columns else df['high'].iloc[-1] - df['low'].iloc[-1]\n",
        "\n",
        "        long_score = 0\n",
        "        short_score = 0\n",
        "        reasons = []\n",
        "\n",
        "        # ========== Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ LONG ==========\n",
        "\n",
        "        # 1. Market Structure Analysis\n",
        "        bullish_structures = [s for s in structures[-3:] if s.direction == 'bullish']\n",
        "        if bullish_structures:\n",
        "            last_bull = bullish_structures[-1]\n",
        "            long_score += 20\n",
        "            reasons.append(f\"Structure: {last_bull.type} Bullish\")\n",
        "\n",
        "            if last_bull.type == 'CHoCH':\n",
        "                long_score += 15\n",
        "                reasons.append(\"CHoCH - ØªØºÛŒÛŒØ± Ø±ÙˆÙ†Ø¯ Ø¨Ù‡ ØµØ¹ÙˆØ¯ÛŒ\")\n",
        "\n",
        "        # 2. Order Block Proximity\n",
        "        bull_obs = [ob for ob in obs if ob.bias == 'bullish' and not ob.touched]\n",
        "        if bull_obs:\n",
        "            nearest = min(bull_obs, key=lambda x: abs(current_price - x.low))\n",
        "            distance = abs(current_price - nearest.low) / current_price\n",
        "\n",
        "            if distance < 0.02:\n",
        "                long_score += 30\n",
        "                reasons.append(f\"OB Bullish Ù‚ÙˆÛŒ (Ù‚Ø¯Ø±Øª: {nearest.strength:.0f}%)\")\n",
        "\n",
        "        # 3. Fair Value Gap\n",
        "        bull_fvgs = [f for f in fvgs if f.bias == 'bullish' and not f.filled]\n",
        "        if bull_fvgs:\n",
        "            for fvg in bull_fvgs:\n",
        "                if fvg.bottom <= current_price <= fvg.top:\n",
        "                    long_score += 15\n",
        "                    reasons.append(\"Ù‚ÛŒÙ…Øª Ø¯Ø± FVG Bullish\")\n",
        "                    break\n",
        "\n",
        "        # 4. Premium/Discount Analysis\n",
        "        if zones.get('current_zone') == 'discount':\n",
        "            long_score += 20\n",
        "            reasons.append(\"Discount Zone - Ù†Ø§Ø­ÛŒÙ‡ Ø®Ø±ÛŒØ¯ Ù…Ù†Ø§Ø³Ø¨\")\n",
        "\n",
        "        # 5. Whale Activity Detection\n",
        "        whale_acc = [w for w in whales[-5:] if w.type == 'accumulation']\n",
        "        if len(whale_acc) >= 2:\n",
        "            long_score += 15\n",
        "            avg_strength = sum(w.strength for w in whale_acc) / len(whale_acc)\n",
        "            reasons.append(f\"Whale Accumulation: {len(whale_acc)} Ù…ÙˆØ±Ø¯ (Ù‚Ø¯Ø±Øª: {avg_strength:.0f}%)\")\n",
        "\n",
        "        # 6. Liquidity Zones\n",
        "        buy_liq = [l for l in liquidity if l.type == 'buy' and abs(current_price - l.price) / current_price < 0.01]\n",
        "        if buy_liq:\n",
        "            long_score += 10\n",
        "            reasons.append(\"Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Buy Liquidity Zone\")\n",
        "\n",
        "        # ========== Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ SHORT ==========\n",
        "\n",
        "        # 1. Market Structure Analysis\n",
        "        bearish_structures = [s for s in structures[-3:] if s.direction == 'bearish']\n",
        "        if bearish_structures:\n",
        "            last_bear = bearish_structures[-1]\n",
        "            short_score += 20\n",
        "            reasons.append(f\"Structure: {last_bear.type} Bearish\")\n",
        "\n",
        "            if last_bear.type == 'CHoCH':\n",
        "                short_score += 15\n",
        "                reasons.append(\"CHoCH - ØªØºÛŒÛŒØ± Ø±ÙˆÙ†Ø¯ Ø¨Ù‡ Ù†Ø²ÙˆÙ„ÛŒ\")\n",
        "\n",
        "        # 2. Order Block Proximity\n",
        "        bear_obs = [ob for ob in obs if ob.bias == 'bearish' and not ob.touched]\n",
        "        if bear_obs:\n",
        "            nearest = min(bear_obs, key=lambda x: abs(current_price - x.high))\n",
        "            distance = abs(current_price - nearest.high) / current_price\n",
        "\n",
        "            if distance < 0.02:\n",
        "                short_score += 30\n",
        "                reasons.append(f\"OB Bearish Ù‚ÙˆÛŒ (Ù‚Ø¯Ø±Øª: {nearest.strength:.0f}%)\")\n",
        "\n",
        "        # 3. Fair Value Gap\n",
        "        bear_fvgs = [f for f in fvgs if f.bias == 'bearish' and not f.filled]\n",
        "        if bear_fvgs:\n",
        "            for fvg in bear_fvgs:\n",
        "                if fvg.bottom <= current_price <= fvg.top:\n",
        "                    short_score += 15\n",
        "                    reasons.append(\"Ù‚ÛŒÙ…Øª Ø¯Ø± FVG Bearish\")\n",
        "                    break\n",
        "\n",
        "        # 4. Premium/Discount Analysis\n",
        "        if zones.get('current_zone') == 'premium':\n",
        "            short_score += 20\n",
        "            reasons.append(\"Premium Zone - Ù†Ø§Ø­ÛŒÙ‡ ÙØ±ÙˆØ´ Ù…Ù†Ø§Ø³Ø¨\")\n",
        "\n",
        "        # 5. Whale Activity Detection\n",
        "        whale_dist = [w for w in whales[-5:] if w.type == 'distribution']\n",
        "        if len(whale_dist) >= 2:\n",
        "            short_score += 15\n",
        "            avg_strength = sum(w.strength for w in whale_dist) / len(whale_dist)\n",
        "            reasons.append(f\"Whale Distribution: {len(whale_dist)} Ù…ÙˆØ±Ø¯ (Ù‚Ø¯Ø±Øª: {avg_strength:.0f}%)\")\n",
        "\n",
        "        # 6. Liquidity Zones\n",
        "        sell_liq = [l for l in liquidity if l.type == 'sell' and abs(current_price - l.price) / current_price < 0.01]\n",
        "        if sell_liq:\n",
        "            short_score += 10\n",
        "            reasons.append(\"Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Sell Liquidity Zone\")\n",
        "\n",
        "        # ========== ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ú©Ù„ÛŒ ==========\n",
        "        if market:\n",
        "            # BTC Trend\n",
        "            btc_trend = market.get('btc_trend', 'neutral')\n",
        "            if btc_trend == 'rising':\n",
        "                long_score += 10\n",
        "                reasons.append(\"BTC Ø¯Ø± Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ\")\n",
        "            elif btc_trend == 'falling':\n",
        "                short_score += 10\n",
        "                reasons.append(\"BTC Ø¯Ø± Ø±ÙˆÙ†Ø¯ Ù†Ø²ÙˆÙ„ÛŒ\")\n",
        "\n",
        "            # USDT Dominance Effect\n",
        "            usdt_d = market.get('usdt_dominance', 0)\n",
        "            if usdt_d > 6:\n",
        "                short_score += 10\n",
        "                reasons.append(f\"USDT.D Ø¨Ø§Ù„Ø§ ({usdt_d:.1f}%) - Risk Off\")\n",
        "\n",
        "            # Market Phase Effect\n",
        "            market_phase = market.get('market_phase', 'neutral')\n",
        "\n",
        "            if market_phase == 'altseason':\n",
        "                if symbol != 'BTC/USDT':\n",
        "                    long_score += 10\n",
        "                    reasons.append(\"Altseason Phase - ÙØ±ØµØª Ø®Ø±ÛŒØ¯ Ø¢Ù„Øªâ€ŒÚ©ÙˆÛŒÙ†\")\n",
        "\n",
        "            elif market_phase == 'bear_market':\n",
        "                short_score += 10\n",
        "                reasons.append(\"Bear Market Phase - Ø¨Ø§Ø²Ø§Ø± Ù†Ø²ÙˆÙ„ÛŒ\")\n",
        "\n",
        "            elif market_phase == 'btc_accumulation':\n",
        "                if symbol == 'BTC/USDT':\n",
        "                    long_score += 10\n",
        "                    reasons.append(\"BTC Accumulation Phase\")\n",
        "\n",
        "        # ========== Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¯Ø§Ù‚Ù„ ØªÙØ§ÙˆØª Ø§Ù…ØªÛŒØ§Ø² ==========\n",
        "        min_score_diff = BOT_SETTINGS.get('min_score_difference', 25)\n",
        "\n",
        "        if abs(long_score - short_score) < min_score_diff:\n",
        "            logger.warning(f\"âš ï¸ ØªØ¶Ø§Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯:\")\n",
        "            logger.warning(f\"   LONG Score: {long_score}\")\n",
        "            logger.warning(f\"   SHORT Score: {short_score}\")\n",
        "            logger.warning(f\"   Ø§Ø®ØªÙ„Ø§Ù: {abs(long_score - short_score)} (Ø­Ø¯Ø§Ù‚Ù„ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²: {min_score_diff})\")\n",
        "            logger.warning(f\"   Ù†ØªÛŒØ¬Ù‡: Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙˆØ§Ø¶Ø­ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ - Ù…Ù†ØªØ¸Ø± Ø³ØªØ§Ù¾ Ø¨Ù‡ØªØ±\")\n",
        "            return None\n",
        "\n",
        "        # ========== ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ ==========\n",
        "        min_score = 60\n",
        "\n",
        "        if long_score > short_score and long_score >= min_score:\n",
        "            direction = 'LONG'\n",
        "            confidence = min(95, long_score)\n",
        "        elif short_score > long_score and short_score >= min_score:\n",
        "            direction = 'SHORT'\n",
        "            confidence = min(95, short_score)\n",
        "        else:\n",
        "            logger.info(f\"Ø§Ù…ØªÛŒØ§Ø² Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù†ÛŒØ³Øª:\")\n",
        "            logger.info(f\"   LONG: {long_score}, SHORT: {short_score} (Ø­Ø¯Ø§Ù‚Ù„: {min_score})\")\n",
        "            return None\n",
        "\n",
        "        # ========== Ù…Ø­Ø§Ø³Ø¨Ù‡ Stop Loss Ùˆ Targets - Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ ==========\n",
        "        entry = current_price\n",
        "        sl_buffer_pct = BOT_SETTINGS.get('sl_buffer_percent', 0.5)\n",
        "\n",
        "        if direction == 'LONG':\n",
        "            swing_highs, swing_lows = self.detect_swing_points(df, 20)\n",
        "\n",
        "            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Stop Loss Ù…Ù†Ø·Ù‚ÛŒ\n",
        "            if len(swing_lows) > 0:\n",
        "                sl = swing_lows.iloc[-1] * (1 - sl_buffer_pct / 100)\n",
        "            else:\n",
        "                sl = entry - atr * 2\n",
        "\n",
        "            # â¬…ï¸ ØªØºÛŒÛŒØ±: Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ SL Ø¨Ø¯ÙˆÙ† Ù…Ø­Ø¯ÙˆØ¯ÛŒØª 3%\n",
        "            if sl >= entry:\n",
        "                logger.warning(\"âš ï¸ SL Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ LONG - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ATR\")\n",
        "                sl = entry - atr * 2\n",
        "\n",
        "            # â¬…ï¸ Ø­Ø°Ù Ø´Ø¯: Ú†Ú© Ú©Ø±Ø¯Ù† Ù…Ø­Ø¯ÙˆØ¯ÛŒØª 3% Ùˆ ØªÙ†Ø¸ÛŒÙ… Ù…Ø¬Ø¯Ø¯ SL\n",
        "            # ÙÙ‚Ø· Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ÛŒØ³Ú© ÙˆØ§Ù‚Ø¹ÛŒ\n",
        "            risk = entry - sl\n",
        "            risk_pct = (risk / entry) * 100\n",
        "\n",
        "            logger.info(f\"ğŸ“Š LONG Setup: Entry={entry:.8f}, SL={sl:.8f}, Risk={risk_pct:.2f}%\")\n",
        "\n",
        "            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Targets\n",
        "            targets = [\n",
        "                entry + risk * 1.5,  # TP1: 1.5R\n",
        "                entry + risk * 2.5,  # TP2: 2.5R\n",
        "                entry + risk * 4.0   # TP3: 4.0R\n",
        "            ]\n",
        "\n",
        "        else:  # SHORT\n",
        "            swing_highs, swing_lows = self.detect_swing_points(df, 20)\n",
        "\n",
        "            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Stop Loss Ù…Ù†Ø·Ù‚ÛŒ\n",
        "            if len(swing_highs) > 0:\n",
        "                sl = swing_highs.iloc[-1] * (1 + sl_buffer_pct / 100)\n",
        "            else:\n",
        "                sl = entry + atr * 2\n",
        "\n",
        "            # â¬…ï¸ ØªØºÛŒÛŒØ±: Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ SL Ø¨Ø¯ÙˆÙ† Ù…Ø­Ø¯ÙˆØ¯ÛŒØª 3%\n",
        "            if sl <= entry:\n",
        "                logger.warning(\"âš ï¸ SL Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ SHORT - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ATR\")\n",
        "                sl = entry + atr * 2\n",
        "\n",
        "            # â¬…ï¸ Ø­Ø°Ù Ø´Ø¯: Ú†Ú© Ú©Ø±Ø¯Ù† Ù…Ø­Ø¯ÙˆØ¯ÛŒØª 3% Ùˆ ØªÙ†Ø¸ÛŒÙ… Ù…Ø¬Ø¯Ø¯ SL\n",
        "            # ÙÙ‚Ø· Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ÛŒØ³Ú© ÙˆØ§Ù‚Ø¹ÛŒ\n",
        "            risk = sl - entry\n",
        "            risk_pct = (risk / entry) * 100\n",
        "\n",
        "            logger.info(f\"ğŸ“Š SHORT Setup: Entry={entry:.8f}, SL={sl:.8f}, Risk={risk_pct:.2f}%\")\n",
        "\n",
        "            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Targets\n",
        "            targets = [\n",
        "                entry - risk * 1.5,  # TP1: 1.5R\n",
        "                entry - risk * 2.5,  # TP2: 2.5R\n",
        "                entry - risk * 4.0   # TP3: 4.0R\n",
        "            ]\n",
        "\n",
        "        # ========== Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ ==========\n",
        "        if direction == 'LONG':\n",
        "            if sl >= entry:\n",
        "                logger.error(\"âŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ LONG Ù†Ø§Ù…Ø¹ØªØ¨Ø±: SL Ø¨Ø§Ù„Ø§ØªØ± Ø§Ø² Entry\")\n",
        "                logger.error(f\"   Entry: {entry:.8f}, SL: {sl:.8f}\")\n",
        "                return None\n",
        "\n",
        "            if any(tp <= entry for tp in targets):\n",
        "                logger.error(\"âŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ LONG Ù†Ø§Ù…Ø¹ØªØ¨Ø±: ÛŒÚ© ÛŒØ§ Ú†Ù†Ø¯ Target Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø§Ø² Entry\")\n",
        "                logger.error(f\"   Entry: {entry:.8f}, Targets: {[f'{t:.8f}' for t in targets]}\")\n",
        "                return None\n",
        "\n",
        "        else:  # SHORT\n",
        "            if sl <= entry:\n",
        "                logger.error(\"âŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ SHORT Ù†Ø§Ù…Ø¹ØªØ¨Ø±: SL Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø§Ø² Entry\")\n",
        "                logger.error(f\"   Entry: {entry:.8f}, SL: {sl:.8f}\")\n",
        "                return None\n",
        "\n",
        "            if any(tp >= entry for tp in targets):\n",
        "                logger.error(\"âŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ SHORT Ù†Ø§Ù…Ø¹ØªØ¨Ø±: ÛŒÚ© ÛŒØ§ Ú†Ù†Ø¯ Target Ø¨Ø§Ù„Ø§ØªØ± Ø§Ø² Entry\")\n",
        "                logger.error(f\"   Entry: {entry:.8f}, Targets: {[f'{t:.8f}' for t in targets]}\")\n",
        "                return None\n",
        "\n",
        "        # ========== Ø§ÛŒØ¬Ø§Ø¯ Ø´ÛŒØ¡ Ø³ÛŒÚ¯Ù†Ø§Ù„ ==========\n",
        "        signal = TradingSignal(\n",
        "            symbol=symbol,\n",
        "            direction=direction,\n",
        "            entry_price=entry,\n",
        "            stop_loss=sl,\n",
        "            targets=targets,\n",
        "            confidence=confidence,\n",
        "            timeframe=tf,\n",
        "            reasons=reasons,\n",
        "            market_context=market,\n",
        "            timestamp=datetime.now()\n",
        "        )\n",
        "\n",
        "        # ========== Ú¯Ø²Ø§Ø±Ø´â€ŒØ¯Ù‡ÛŒ Ú©Ø§Ù…Ù„ ==========\n",
        "        logger.info(f\"\\n{'='*70}\")\n",
        "        logger.info(f\"âœ… {direction} Signal Generated / Ø³ÛŒÚ¯Ù†Ø§Ù„ {direction} ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯\")\n",
        "        logger.info(f\"{'='*70}\")\n",
        "        logger.info(f\"ğŸ“Š Symbol: {symbol}\")\n",
        "        logger.info(f\"â° Timeframe: {tf}\")\n",
        "        logger.info(f\"ğŸ¯ Confidence: {confidence:.0f}%\")\n",
        "        logger.info(f\"ğŸ’° Entry: {entry:.8f}\")\n",
        "        logger.info(f\"ğŸ›¡ï¸ Stop Loss: {sl:.8f} (Risk: {signal.risk_percent:.2f}%)\")\n",
        "        logger.info(f\"ğŸ“ˆ Risk/Reward: 1:{signal.risk_reward:.2f}\")\n",
        "        logger.info(f\"\\nğŸ¯ Targets:\")\n",
        "        logger.info(f\"   TP1: {targets[0]:.8f} (1.5R)\")\n",
        "        logger.info(f\"   TP2: {targets[1]:.8f} (2.5R)\")\n",
        "        logger.info(f\"   TP3: {targets[2]:.8f} (4.0R)\")\n",
        "        logger.info(f\"\\nğŸ“‹ Reasons ({len(reasons)}):\")\n",
        "        for i, reason in enumerate(reasons, 1):\n",
        "            logger.info(f\"   {i}. {reason}\")\n",
        "        logger.info(f\"\\nğŸ’¡ Position Size:\")\n",
        "        logger.info(f\"   {signal.position_size_recommendation}\")\n",
        "        logger.info(f\"{'='*70}\\n\")\n",
        "\n",
        "        return signal\n",
        "\n",
        "# ==================== Ø¨Ø®Ø´ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡: create_advanced_chart ====================\n",
        "\n",
        "    def create_advanced_chart(\n",
        "        self, symbol: str, df: pd.DataFrame, signal: TradingSignal,\n",
        "        structures: List[MarketStructure],\n",
        "        obs: List[OrderBlock],\n",
        "        fvgs: List[FairValueGap],\n",
        "        zones: Dict,\n",
        "        whales: List[WhaleActivity],\n",
        "        liquidity: List[LiquidityZone]\n",
        "    ) -> str:\n",
        "        \"\"\"Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø± Ø¨Ø§ fallback Ø¨Ù‡ matplotlib\"\"\"\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ kaleido\n",
        "        try:\n",
        "            import kaleido\n",
        "            has_kaleido = True\n",
        "        except ImportError:\n",
        "            has_kaleido = False\n",
        "            logger.warning(\"âš ï¸ Kaleido Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² matplotlib\")\n",
        "\n",
        "        if has_kaleido:\n",
        "            try:\n",
        "                # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Plotly\n",
        "                fig = make_subplots(\n",
        "                    rows=2, cols=1,\n",
        "                    shared_xaxes=True,\n",
        "                    vertical_spacing=0.05,\n",
        "                    row_heights=[0.7, 0.3],\n",
        "                    subplot_titles=(f'{symbol} - {signal.timeframe}', 'Volume')\n",
        "                )\n",
        "\n",
        "                # Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§\n",
        "                fig.add_trace(\n",
        "                    go.Candlestick(\n",
        "                        x=df.index,\n",
        "                        open=df['open'],\n",
        "                        high=df['high'],\n",
        "                        low=df['low'],\n",
        "                        close=df['close'],\n",
        "                        name='Price',\n",
        "                        increasing_line_color='#26a69a',\n",
        "                        decreasing_line_color='#ef5350'\n",
        "                    ),\n",
        "                    row=1, col=1\n",
        "                )\n",
        "\n",
        "                # Order Blocks\n",
        "                for ob in obs[:3]:\n",
        "                    ob_time = pd.to_datetime(ob.time, unit='ms')\n",
        "                    if ob_time not in df.index:\n",
        "                        continue\n",
        "\n",
        "                    color = 'rgba(8, 153, 129, 0.3)' if ob.bias == 'bullish' else 'rgba(242, 54, 69, 0.3)'\n",
        "\n",
        "                    fig.add_shape(\n",
        "                        type='rect',\n",
        "                        x0=ob_time, x1=df.index[-1],\n",
        "                        y0=ob.low, y1=ob.high,\n",
        "                        fillcolor=color,\n",
        "                        line=dict(color=color.replace('0.3', '0.8'), width=1),\n",
        "                        row=1, col=1\n",
        "                    )\n",
        "\n",
        "                # Premium/Discount\n",
        "                if zones:\n",
        "                    fig.add_shape(\n",
        "                        type='rect',\n",
        "                        x0=df.index[0], x1=df.index[-1],\n",
        "                        y0=zones['premium']['bottom'], y1=zones['premium']['top'],\n",
        "                        fillcolor='rgba(244, 67, 54, 0.1)',\n",
        "                        line=dict(width=0),\n",
        "                        row=1, col=1\n",
        "                    )\n",
        "\n",
        "                    fig.add_shape(\n",
        "                        type='rect',\n",
        "                        x0=df.index[0], x1=df.index[-1],\n",
        "                        y0=zones['discount']['bottom'], y1=zones['discount']['top'],\n",
        "                        fillcolor='rgba(76, 175, 80, 0.1)',\n",
        "                        line=dict(width=0),\n",
        "                        row=1, col=1\n",
        "                    )\n",
        "\n",
        "                # Signal\n",
        "                entry_color = '#00ff00' if signal.direction == 'LONG' else '#ff0000'\n",
        "                fig.add_trace(\n",
        "                    go.Scatter(\n",
        "                        x=[df.index[-1]], y=[signal.entry_price],\n",
        "                        mode='markers',\n",
        "                        marker=dict(size=20, color=entry_color, symbol='star'),\n",
        "                        name=f'{signal.direction} Entry'\n",
        "                    ),\n",
        "                    row=1, col=1\n",
        "                )\n",
        "\n",
        "                # SL & TP\n",
        "                fig.add_shape(\n",
        "                    type='line',\n",
        "                    x0=df.index[0], x1=df.index[-1],\n",
        "                    y0=signal.stop_loss, y1=signal.stop_loss,\n",
        "                    line=dict(color='red', width=2, dash='dash'),\n",
        "                    row=1, col=1\n",
        "                )\n",
        "\n",
        "                for i, tp in enumerate(signal.targets):\n",
        "                    fig.add_shape(\n",
        "                        type='line',\n",
        "                        x0=df.index[0], x1=df.index[-1],\n",
        "                        y0=tp, y1=tp,\n",
        "                        line=dict(color=['#ffeb3b', '#ff9800', '#4caf50'][i], width=2, dash='dot'),\n",
        "                        row=1, col=1\n",
        "                    )\n",
        "\n",
        "                # Volume\n",
        "                colors = ['#26a69a' if c >= o else '#ef5350' for c, o in zip(df['close'], df['open'])]\n",
        "                fig.add_trace(\n",
        "                    go.Bar(x=df.index, y=df['volume'], marker=dict(color=colors), name='Volume'),\n",
        "                    row=2, col=1\n",
        "                )\n",
        "\n",
        "                # Layout\n",
        "                title = f\"{signal.direction} {symbol} | {signal.timeframe} | {signal.confidence:.0f}%\"\n",
        "                fig.update_layout(\n",
        "                    title=title,\n",
        "                    template='plotly_dark',\n",
        "                    height=800,\n",
        "                    xaxis_rangeslider_visible=False\n",
        "                )\n",
        "\n",
        "                chart_path = f\"{BASE_DIR}/charts/{symbol.replace('/', '_')}_{signal.timeframe}_{int(time.time())}.png\"\n",
        "                fig.write_image(chart_path, width=1600, height=800, engine='kaleido')\n",
        "                logger.info(f\"âœ… Ù†Ù…ÙˆØ¯Ø§Ø± Plotly Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {chart_path}\")\n",
        "                return chart_path\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Ø®Ø·Ø§ Ø¯Ø± Plotly: {e} - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² matplotlib\")\n",
        "\n",
        "        # Fallback Ø¨Ù‡ matplotlib\n",
        "        return self.create_fallback_chart(symbol, df, signal, obs, zones)\n",
        "\n",
        "\n",
        "    def create_fallback_chart(self, symbol: str, df: pd.DataFrame, signal: TradingSignal,\n",
        "                            obs: List[OrderBlock], zones: Dict) -> str:\n",
        "        \"\"\"Ù†Ù…ÙˆØ¯Ø§Ø± matplotlib (Ù‡Ù…ÛŒØ´Ù‡ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯)\"\"\"\n",
        "        plt.style.use('dark_background')\n",
        "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 10), height_ratios=[3, 1], sharex=True)\n",
        "\n",
        "        # Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§\n",
        "        colors = ['#26a69a' if c >= o else '#ef5350' for c, o in zip(df['close'], df['open'])]\n",
        "\n",
        "        for i in range(len(df)):\n",
        "            ax1.plot([i, i], [df['low'].iloc[i], df['high'].iloc[i]], color=colors[i], linewidth=1)\n",
        "            body_h = abs(df['close'].iloc[i] - df['open'].iloc[i])\n",
        "            body_b = min(df['open'].iloc[i], df['close'].iloc[i])\n",
        "            ax1.add_patch(Rectangle((i-0.3, body_b), 0.6, body_h,\n",
        "                                    facecolor=colors[i], edgecolor=colors[i], alpha=0.8))\n",
        "\n",
        "        # Order Blocks\n",
        "        for ob in obs[:3]:\n",
        "            ob_time = pd.to_datetime(ob.time, unit='ms')\n",
        "            if ob_time in df.index:\n",
        "                ob_idx = df.index.get_loc(ob_time)\n",
        "                color = '#089981' if ob.bias == 'bullish' else '#f23645'\n",
        "                ax1.add_patch(Rectangle((ob_idx, ob.low), len(df)-ob_idx, ob.high-ob.low,\n",
        "                                        facecolor=color, alpha=0.2, edgecolor=color, linewidth=1))\n",
        "\n",
        "        # Signal\n",
        "        current_idx = len(df) - 1\n",
        "        entry_color = '#00ff00' if signal.direction == 'LONG' else '#ff0000'\n",
        "        ax1.scatter(current_idx, signal.entry_price, color=entry_color, marker='*',\n",
        "                s=400, zorder=10, edgecolors='white', linewidths=2)\n",
        "\n",
        "        # SL & TP\n",
        "        ax1.axhline(signal.stop_loss, color='red', linestyle='--', linewidth=2, alpha=0.7, label='SL')\n",
        "        for i, tp in enumerate(signal.targets):\n",
        "            ax1.axhline(tp, color=['#ffeb3b', '#ff9800', '#4caf50'][i],\n",
        "                    linestyle='-.', linewidth=2, alpha=0.7, label=f'TP{i+1}')\n",
        "\n",
        "        ax1.set_ylabel('Price', fontsize=11)\n",
        "        ax1.grid(True, alpha=0.2)\n",
        "        ax1.legend(loc='upper left')\n",
        "\n",
        "        # Volume\n",
        "        ax2.bar(range(len(df)), df['volume'], color=colors, alpha=0.6)\n",
        "        ax2.set_ylabel('Volume', fontsize=11)\n",
        "        ax2.grid(True, alpha=0.2)\n",
        "\n",
        "        title = f\"{signal.direction} {symbol} | {signal.timeframe} | {signal.confidence:.0f}% | R:R 1:{signal.risk_reward:.1f}\"\n",
        "        fig.suptitle(title, fontsize=14, weight='bold')\n",
        "\n",
        "        chart_path = f\"{BASE_DIR}/charts/{symbol.replace('/', '_')}_{signal.timeframe}_{int(time.time())}.png\"\n",
        "        plt.savefig(chart_path, dpi=120, bbox_inches='tight', facecolor='#0d1117')\n",
        "        plt.close()\n",
        "\n",
        "        logger.info(f\"âœ… Ù†Ù…ÙˆØ¯Ø§Ø± matplotlib Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {chart_path}\")\n",
        "        return chart_path\n",
        "\n",
        "    def analyze_symbol(self, symbol: str, timeframes: List[str] = ['1h', '4h']) -> List[TradingSignal]:\n",
        "        \"\"\"\n",
        "        ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ ÛŒÚ© Ø§Ø±Ø² Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù\n",
        "        Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ù…Ù„ Ø­Ø§ÙØ¸Ù‡ Ùˆ Ù…Ù†Ø§Ø¨Ø¹\n",
        "        \"\"\"\n",
        "        logger.info(f\"\\n{'='*70}\")\n",
        "        logger.info(f\"Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ {symbol}\")\n",
        "        logger.info(f\"{'='*70}\")\n",
        "\n",
        "        signals = []\n",
        "\n",
        "        # Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª Ø¨Ø§Ø²Ø§Ø±\n",
        "        market = self.fetch_market_dominance()\n",
        "\n",
        "        for tf in timeframes:\n",
        "            logger.info(f\"\\n{'---'*20}\")\n",
        "            logger.info(f\"ØªØ­Ù„ÛŒÙ„ Timeframe: {tf}\")\n",
        "            logger.info(f\"{'---'*20}\")\n",
        "\n",
        "            try:\n",
        "                # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡\n",
        "                df = self.fetch_ohlcv_with_cache(symbol, tf, limit=500)\n",
        "\n",
        "                if df is None or len(df) < 100:\n",
        "                    logger.warning(f\"Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ³Øª: {symbol} Ø¯Ø± {tf}\")\n",
        "                    logger.warning(f\"ØªØ¹Ø¯Ø§Ø¯ Ú©Ù†Ø¯Ù„: {len(df) if df is not None else 0}\")\n",
        "                    continue\n",
        "\n",
        "                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§\n",
        "                logger.info(\"Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§...\")\n",
        "                df['atr'] = ta.volatility.average_true_range(\n",
        "                    df['high'], df['low'], df['close'], window=14\n",
        "                )\n",
        "\n",
        "                # ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Smart Money Concepts\n",
        "                logger.info(\"ØªØ­Ù„ÛŒÙ„ Market Structure...\")\n",
        "                structures = self.detect_market_structure(df, tf)\n",
        "\n",
        "                logger.info(\"ØªØ­Ù„ÛŒÙ„ Order Blocks...\")\n",
        "                obs = self.detect_order_blocks(df, structures)\n",
        "\n",
        "                logger.info(\"ØªØ­Ù„ÛŒÙ„ Fair Value Gaps...\")\n",
        "                fvgs = self.detect_fvg(df)\n",
        "\n",
        "                logger.info(\"Ù…Ø­Ø§Ø³Ø¨Ù‡ Premium/Discount Zones...\")\n",
        "                zones = self.calculate_zones(df)\n",
        "\n",
        "                logger.info(\"ØªØ´Ø®ÛŒØµ Whale Activity...\")\n",
        "                whales = self.detect_whale_activity(df)\n",
        "\n",
        "                logger.info(\"ØªØ­Ù„ÛŒÙ„ Liquidity Zones...\")\n",
        "                liquidity = self.detect_liquidity_zones(df)\n",
        "\n",
        "                # ØªÙˆÙ„ÛŒØ¯ Ø³ÛŒÚ¯Ù†Ø§Ù„\n",
        "                logger.info(\"ØªÙˆÙ„ÛŒØ¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ...\")\n",
        "                signal = self.generate_signal(\n",
        "                    symbol, tf, df, structures, obs, fvgs,\n",
        "                    zones, whales, liquidity, market\n",
        "                )\n",
        "\n",
        "                if signal:\n",
        "                    logger.info(f\"âœ… Ø³ÛŒÚ¯Ù†Ø§Ù„ {signal.direction} Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† {signal.confidence:.0f}% ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯\")\n",
        "\n",
        "                    # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "                    logger.info(\"Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø± ØªØ­Ù„ÛŒÙ„ÛŒ...\")\n",
        "                    chart_path = self.create_advanced_chart(\n",
        "                        symbol, df, signal, structures, obs, fvgs,\n",
        "                        zones, whales, liquidity\n",
        "                    )\n",
        "                    signal.chart_path = chart_path\n",
        "\n",
        "                    signals.append(signal)\n",
        "                else:\n",
        "                    logger.info(f\"â„¹ï¸ Ø³ÛŒÚ¯Ù†Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø± {tf} ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ {symbol} Ø¯Ø± {tf}: {e}\")\n",
        "                logger.error(traceback.format_exc())\n",
        "\n",
        "            finally:\n",
        "                # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡\n",
        "                if 'df' in locals():\n",
        "                    del df\n",
        "                gc.collect()\n",
        "\n",
        "                # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ù†Ø§Ø¨Ø¹\n",
        "                resources = monitor_resources()\n",
        "                if resources:\n",
        "                    logger.info(f\"ÙˆØ¶Ø¹ÛŒØª Ù…Ù†Ø§Ø¨Ø¹: RAM={resources.get('memory_percent', 0):.1f}%, \"\n",
        "                              f\"Cache Items={resources.get('cache_items', 0)}\")\n",
        "\n",
        "                # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ\n",
        "                cleanup_drive_files()\n",
        "\n",
        "        # Ø®Ù„Ø§ØµÙ‡ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "        logger.info(f\"\\n{'='*70}\")\n",
        "        logger.info(f\"ØªØ­Ù„ÛŒÙ„ {symbol} ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯\")\n",
        "        logger.info(f\"ØªØ¹Ø¯Ø§Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡: {len(signals)}\")\n",
        "        if signals:\n",
        "            for sig in signals:\n",
        "                logger.info(f\"  - {sig.timeframe}: {sig.direction} ({sig.confidence:.0f}%)\")\n",
        "        logger.info(f\"{'='*70}\\n\")\n",
        "\n",
        "        return signals\n",
        "\n",
        "\n",
        "# ==================== Ú©Ù„Ø§Ø³ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… ====================\n",
        "# ==================== Ú©Ù„Ø§Ø³ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… - Ù†Ø³Ø®Ù‡ Ú©Ø§Ù…Ù„ ====================\n",
        "\n",
        "import asyncio\n",
        "from collections import defaultdict\n",
        "\n",
        "class TelegramBot:\n",
        "    \"\"\"Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù„\"\"\"\n",
        "\n",
        "    def __init__(self, token: str, channel_id: str):\n",
        "        self.token = token\n",
        "        self.channel_id = channel_id\n",
        "        self.analyzer = SmartMoneyWhaleHunter()\n",
        "        self.hunter = SmartMoneyWhaleHunter()\n",
        "        self.app = None\n",
        "\n",
        "        if not TELEGRAM_AVAILABLE:\n",
        "            logger.warning(\"âš ï¸ ØªÙ„Ú¯Ø±Ø§Ù… ØºÛŒØ±ÙØ¹Ø§Ù„ - ÙÙ‚Ø· ØªØ­Ù„ÛŒÙ„ Ù…Ø³ØªÙ‚ÛŒÙ… Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ø§Ø³Øª\")\n",
        "\n",
        "    def log_user_activity(self, user_id: int, username: str, symbol: str, action: str):\n",
        "        \"\"\"Ø«Ø¨Øª ÙØ¹Ø§Ù„ÛŒØª Ú©Ø§Ø±Ø¨Ø±Ø§Ù†\"\"\"\n",
        "        try:\n",
        "            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "            log_entry = f\"[{timestamp}] User: {username} (ID: {user_id}) | Action: {action} | Symbol: {symbol}\"\n",
        "\n",
        "            # Ù„Ø§Ú¯ Ø¯Ø± ÙØ§ÛŒÙ„\n",
        "            logger.info(f\"ğŸ‘¤ {log_entry}\")\n",
        "\n",
        "            # Ù„Ø§Ú¯ Ø¯Ø± ÙØ§ÛŒÙ„ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ø¢Ù…Ø§Ø±\n",
        "            stats_file = f\"{BASE_DIR}/logs/user_stats.log\"\n",
        "            with open(stats_file, 'a', encoding='utf-8') as f:\n",
        "                f.write(log_entry + '\\n')\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ø«Ø¨Øª Ù„Ø§Ú¯ Ú©Ø§Ø±Ø¨Ø±: {e}\")\n",
        "\n",
        "    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "        \"\"\"Ø¯Ø³ØªÙˆØ± /start\"\"\"\n",
        "        msg = \"\"\"\n",
        "ğŸ‹ **Smart Money Whale Hunter Bot**\n",
        "**Professional Trading Signal System**\n",
        "\n",
        "**ğŸ“‹ Ø¯Ø³ØªÙˆØ±Ø§Øª:**\n",
        "â€¢ `/analyze BTC/USDT` - ØªØ­Ù„ÛŒÙ„ Ø§Ø±Ø² (1h & 4h)\n",
        "â€¢ `/analyze ETH/USDT 1h` - ØªØ­Ù„ÛŒÙ„ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… Ø®Ø§Øµ\n",
        "â€¢ `/analyze SOL/USDT 4h` - ØªØ­Ù„ÛŒÙ„ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… Ø®Ø§Øµ\n",
        "â€¢ `/help` - Ø±Ø§Ù‡Ù†Ù…Ø§\n",
        "â€¢ `/stats` - Ø¢Ù…Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ (ÙÙ‚Ø· Ø§Ø¯Ù…ÛŒÙ†)\n",
        "\n",
        "**âœ¨ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§:**\n",
        "âœ… Smart Money Concepts (SMC)\n",
        "âœ… ØªØ´Ø®ÛŒØµ Order Blocks\n",
        "âœ… Fair Value Gaps (FVG)\n",
        "âœ… Market Structure (BOS/CHoCH)\n",
        "âœ… Whale Activity Detection\n",
        "âœ… USDT Dominance Analysis\n",
        "âœ… Market Phase Detection\n",
        "âœ… Ù…Ø¯ÛŒØ±ÛŒØª Ø±ÛŒØ³Ú© Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ (Ø­Ø¯Ø§Ú©Ø«Ø± 3%)\n",
        "âœ… Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ú©Ø§Ù…Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§\n",
        "âœ… Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡\n",
        "\n",
        "**âš ï¸ ØªÙˆØ¬Ù‡:**\n",
        "Ø§ÛŒÙ† Ø±Ø¨Ø§Øª ÛŒÚ© Ø§Ø¨Ø²Ø§Ø± Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø³Øª.\n",
        "Ù‡Ù…ÛŒØ´Ù‡ ØªØ­Ù‚ÛŒÙ‚Ø§Øª Ø´Ø®ØµÛŒ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø±ÛŒØ³Ú© Ø±Ø§ Ø±Ø¹Ø§ÛŒØª Ú©Ù†ÛŒØ¯.\n",
        "\n",
        "ØªÙˆØ³Ø¹Ù‡: Ø­Ø³ÛŒÙ† ÙØ§ÛŒÙ†Ù†Ø³ ğŸ¤–\n",
        "Ù†Ø³Ø®Ù‡: 2.1 Enhanced\n",
        "        \"\"\"\n",
        "        await update.message.reply_text(msg, parse_mode='Markdown')\n",
        "\n",
        "    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "        \"\"\"Ø¯Ø³ØªÙˆØ± /help\"\"\"\n",
        "        msg = \"\"\"\n",
        "ğŸ“š Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡\n",
        "\n",
        "ğŸ” Ù†Ø­ÙˆÙ‡ ØªØ­Ù„ÛŒÙ„:\n",
        "- /analyze BTC/USDT - ØªØ­Ù„ÛŒÙ„ Ø¯Ø± 1h Ùˆ 4h\n",
        "- /analyze ETH/USDT 1h - ÙÙ‚Ø· 1h\n",
        "- /analyze BNB/USDT 4h - ÙÙ‚Ø· 4h\n",
        "\n",
        "â±ï¸ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø´Ø¯Ù‡:\n",
        "- 15m - Ù¾Ø§Ù†Ø²Ø¯Ù‡ Ø¯Ù‚ÛŒÙ‚Ù‡ (Ø§Ø³Ú©Ø§Ù„Ù¾)\n",
        "- 1h - ÛŒÚ© Ø³Ø§Ø¹Øª (Ø³ÙˆØ¦ÛŒÙ†Ú¯ Ú©ÙˆØªØ§Ù‡)\n",
        "- 4h - Ú†Ù‡Ø§Ø± Ø³Ø§Ø¹Øª (Ø³ÙˆØ¦ÛŒÙ†Ú¯)\n",
        "- 1d - Ø±ÙˆØ²Ø§Ù†Ù‡ (Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª)\n",
        "\n",
        "ğŸ“Š ØªÙˆØ¶ÛŒØ­ Ø§Ù„Ù…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„:\n",
        "\n",
        "1. Entry (ÙˆØ±ÙˆØ¯):\n",
        "Ù‚ÛŒÙ…Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ ÙˆØ±ÙˆØ¯ Ø¨Ù‡ Ù…Ø¹Ø§Ù…Ù„Ù‡\n",
        "\n",
        "2. Stop Loss (Ø­Ø¯ Ø¶Ø±Ø±):\n",
        "Ù†Ù‚Ø·Ù‡ Ø®Ø±ÙˆØ¬ Ø¯Ø± ØµÙˆØ±Øª Ø®Ù„Ø§Ù Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ\n",
        "Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ SMC ØªØ¹ÛŒÛŒÙ† Ù…ÛŒâ€ŒØ´ÙˆØ¯\n",
        "\n",
        "3. Take Profit (Ø§Ù‡Ø¯Ø§Ù Ø³ÙˆØ¯):\n",
        "â€¢ TP1: Ù‡Ø¯Ù Ø§ÙˆÙ„ (1.5R)\n",
        "â€¢ TP2: Ù‡Ø¯Ù Ø¯ÙˆÙ… (2.5R)\n",
        "â€¢ TP3: Ù‡Ø¯Ù Ø³ÙˆÙ… (4.0R)\n",
        "\n",
        "4. Confidence (Ø§Ø·Ù…ÛŒÙ†Ø§Ù†):\n",
        "Ø¯Ø±ØµØ¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø³ÛŒÚ¯Ù†Ø§Ù„ (60-95%)\n",
        "Ø¨Ø§Ù„Ø§ØªØ± = Ù‚ÙˆÛŒâ€ŒØªØ±\n",
        "\n",
        "5. R:R (Risk/Reward):\n",
        "Ù†Ø³Ø¨Øª Ø±ÛŒØ³Ú© Ø¨Ù‡ Ø±ÛŒÙˆØ§Ø±Ø¯\n",
        "Ø­Ø¯Ø§Ù‚Ù„ 1:1.5 ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯\n",
        "\n",
        "ğŸ“– Ø§ØµØ·Ù„Ø§Ø­Ø§Øª SMC:\n",
        "\n",
        "- BOS (Break of Structure):\n",
        "Ø´Ú©Ø³Øª Ø³Ø§Ø®ØªØ§Ø± - Ø§Ø¯Ø§Ù…Ù‡ Ø±ÙˆÙ†Ø¯\n",
        "\n",
        "- CHoCH (Change of Character):\n",
        "ØªØºÛŒÛŒØ± Ø±ÙˆÙ†Ø¯ - Ù…Ø¹Ú©ÙˆØ³ Ø´Ø¯Ù†\n",
        "\n",
        "- OB (Order Block):\n",
        "Ø¨Ù„ÙˆÚ© Ø³ÙØ§Ø±Ø´ - Ù†Ø§Ø­ÛŒÙ‡ ÙˆØ±ÙˆØ¯ Ù†Ù‡Ù†Ú¯â€ŒÙ‡Ø§\n",
        "\n",
        "- FVG (Fair Value Gap):\n",
        "Ø´Ú©Ø§Ù Ù‚ÛŒÙ…ØªÛŒ - Ù†Ø§Ø­ÛŒÙ‡ Ù¾Ø±Ø´Ø¯Ù†ÛŒ\n",
        "\n",
        "- Premium Zone:\n",
        "Ù†Ø§Ø­ÛŒÙ‡ Ú¯Ø±Ø§Ù† - Ù…Ù†Ø§Ø³Ø¨ ÙØ±ÙˆØ´\n",
        "\n",
        "- Discount Zone:\n",
        "Ù†Ø§Ø­ÛŒÙ‡ Ø§Ø±Ø²Ø§Ù† - Ù…Ù†Ø§Ø³Ø¨ Ø®Ø±ÛŒØ¯\n",
        "\n",
        "ğŸŒ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±:\n",
        "\n",
        "- BTC Dominance (BTC.D):\n",
        "Ø¯Ø±ØµØ¯ Ø³Ù‡Ù… Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ† Ø§Ø² Ø¨Ø§Ø²Ø§Ø±\n",
        "Ø¨Ø§Ù„Ø§ = Ù‚Ø¯Ø±Øª BTCØŒ Ù¾Ø§ÛŒÛŒÙ† = Altseason\n",
        "\n",
        "- USDT Dominance (USDT.D):\n",
        "Ø¯Ø±ØµØ¯ Ø³Ù‡Ù… ØªØªØ± Ø§Ø² Ø¨Ø§Ø²Ø§Ø±\n",
        "Ø¨Ø§Ù„Ø§ (>6%) = Ø®Ø±ÙˆØ¬ Ù¾ÙˆÙ„ (Risk-Off)\n",
        "Ù¾Ø§ÛŒÛŒÙ† (<6%) = ÙˆØ±ÙˆØ¯ Ù¾ÙˆÙ„ (Risk-On)\n",
        "\n",
        "- Market Phase:\n",
        "- Altseason: ÙØ±ØµØª Ø¢Ù„Øªâ€ŒÚ©ÙˆÛŒÙ†\n",
        "- Bear Market: Ø¨Ø§Ø²Ø§Ø± Ù†Ø²ÙˆÙ„ÛŒ\n",
        "- BTC Accumulation: Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ†\n",
        "- Neutral: Ø¨Ø§Ø²Ø§Ø± Ø®Ù†Ø«ÛŒ\n",
        "\n",
        "ğŸ’¡ Ù†Ú©Ø§Øª Ù…Ù‡Ù…:\n",
        "\n",
        "1. Ù…Ø¯ÛŒØ±ÛŒØª Ø±ÛŒØ³Ú©:\n",
        "Ø­Ø¯Ø§Ú©Ø«Ø± 1-2% Ø³Ø±Ù…Ø§ÛŒÙ‡ Ø¯Ø± Ù‡Ø± Ù…Ø¹Ø§Ù…Ù„Ù‡\n",
        "\n",
        "2. Position Sizing:\n",
        "Ø­Ø¬Ù… = (Ø³Ø±Ù…Ø§ÛŒÙ‡ Ã— Ø±ÛŒØ³Ú©%) / (ÙØ§ØµÙ„Ù‡ ØªØ§ SL)\n",
        "\n",
        "3. ØªØ§ÛŒÛŒØ¯ Ú†Ù†Ø¯Ú¯Ø§Ù†Ù‡:\n",
        "Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù‚ÙˆÛŒ = Ù‡Ù…Ú¯Ø±Ø§ÛŒÛŒ Ú†Ù†Ø¯ ÙØ§Ú©ØªÙˆØ±\n",
        "\n",
        "4. Stop Loss:\n",
        "NEVER Ù…Ø¹Ø§Ù…Ù„Ù‡ Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªØ§Ù¾ Ù„Ø§Ø³\n",
        "\n",
        "5. Take Profit:\n",
        "Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù¾Ù„Ù‡â€ŒØ§ÛŒ (TP1: 50%, TP2: 30%, TP3: 20%) Ø®Ø§Ø±Ø¬ Ø´ÙˆÛŒØ¯\n",
        "\n",
        "âš ï¸ Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§:\n",
        "\n",
        "âŒ Ø§ÛŒÙ† Ø±Ø¨Ø§Øª Ù…Ø´Ø§ÙˆØ± Ù…Ø§Ù„ÛŒ Ù†ÛŒØ³Øª\n",
        "âŒ DYOR (ØªØ­Ù‚ÛŒÙ‚ Ø´Ø®ØµÛŒ) Ø§Ù„Ø²Ø§Ù…ÛŒ\n",
        "âŒ Ø³Ø±Ù…Ø§ÛŒÙ‡â€ŒØ§ÛŒ Ú©Ù‡ ØªÙˆØ§Ù† Ø§Ø² Ø¯Ø³Øª Ø¯Ø§Ø¯Ù†Ø´ Ø±Ø§ Ù†Ø¯Ø§Ø±ÛŒØ¯ ÙˆØ§Ø±Ø¯ Ù†Ú©Ù†ÛŒØ¯\n",
        "âŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø±Ø§ Ú©Ù†Ø§Ø± Ø¨Ú¯Ø°Ø§Ø±ÛŒØ¯\n",
        "âŒ Ø¨Ù‡ ÛŒÚ© Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø§Ú©ØªÙØ§ Ù†Ú©Ù†ÛŒØ¯\n",
        "\n",
        "ğŸ†˜ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ:\n",
        "Ø¨Ø±Ø§ÛŒ Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø§Ú¯ ÛŒØ§ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: @FINANCE_HOSSEIN\n",
        "\n",
        "Ù…ÙˆÙÙ‚ Ø¨Ø§Ø´ÛŒØ¯! ğŸš€\n",
        "        \"\"\"\n",
        "        await update.message.reply_text(msg)\n",
        "\n",
        "    async def stats_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "        \"\"\"Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ (ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ù…ÛŒÙ†)\"\"\"\n",
        "        user = update.effective_user\n",
        "        user_id = user.id\n",
        "        username = user.username\n",
        "\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø§Ø¯Ù…ÛŒÙ†\n",
        "        if user_id not in ADMIN_USERS and (not username or f\"@{username}\" not in ADMIN_USERS):\n",
        "            await update.message.reply_text(\"âŒ Ø´Ù…Ø§ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø§ÛŒÙ† Ø¯Ø³ØªÙˆØ± Ù†Ø¯Ø§Ø±ÛŒØ¯.\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            stats_file = f\"{BASE_DIR}/logs/user_stats.log\"\n",
        "\n",
        "            if not os.path.exists(stats_file):\n",
        "                await update.message.reply_text(\"â„¹ï¸ Ù‡Ù†ÙˆØ² Ø¢Ù…Ø§Ø±ÛŒ Ø«Ø¨Øª Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.\")\n",
        "                return\n",
        "\n",
        "            # Ø®ÙˆØ§Ù†Ø¯Ù† Ùˆ ØªØ­Ù„ÛŒÙ„ Ù„Ø§Ú¯â€ŒÙ‡Ø§\n",
        "            with open(stats_file, 'r', encoding='utf-8') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            # Ø¢Ù…Ø§Ø±Ú¯ÛŒØ±ÛŒ\n",
        "            total_requests = len(lines)\n",
        "            users = set()\n",
        "            symbols = defaultdict(int)\n",
        "            timeframes = defaultdict(int)\n",
        "\n",
        "            for line in lines:\n",
        "                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø² Ù„Ø§Ú¯\n",
        "                if 'User:' in line and 'Symbol:' in line:\n",
        "                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ø±Ø¨Ø±\n",
        "                    try:\n",
        "                        user_part = line.split('User:')[1].split('(ID:')[0].strip()\n",
        "                        users.add(user_part)\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ symbol\n",
        "                    try:\n",
        "                        symbol_part = line.split('Symbol:')[1].strip()\n",
        "                        if '|' in symbol_part:\n",
        "                            symbol_part = symbol_part.split('|')[0].strip()\n",
        "                        symbols[symbol_part] += 1\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ timeframe\n",
        "                    try:\n",
        "                        if 'analyze_' in line:\n",
        "                            tf_part = line.split('analyze_')[1].strip()\n",
        "                            if '|' in tf_part:\n",
        "                                tf_part = tf_part.split('|')[0].strip()\n",
        "                            timeframes[tf_part] += 1\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "            # Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù… Ø¢Ù…Ø§Ø±\n",
        "            msg = \"ğŸ“Š **Ø¢Ù…Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ø¨Ø§Øª**\\n\"\n",
        "            msg += \"â•\" * 30 + \"\\n\\n\"\n",
        "\n",
        "            msg += f\"ğŸ‘¥ **ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†:** {len(users)}\\n\"\n",
        "            msg += f\"ğŸ“ˆ **ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§:** {total_requests}\\n\\n\"\n",
        "\n",
        "            # Ù…Ø­Ø¨ÙˆØ¨â€ŒØªØ±ÛŒÙ† Ø§Ø±Ø²Ù‡Ø§\n",
        "            if symbols:\n",
        "                msg += \"ğŸ’ **Ù…Ø­Ø¨ÙˆØ¨â€ŒØªØ±ÛŒÙ† Ø§Ø±Ø²Ù‡Ø§:**\\n\"\n",
        "                sorted_symbols = sorted(symbols.items(), key=lambda x: x[1], reverse=True)\n",
        "                for i, (sym, count) in enumerate(sorted_symbols[:10], 1):\n",
        "                    percentage = (count / total_requests) * 100\n",
        "                    msg += f\"{i}. `{sym}`: {count} Ø¨Ø§Ø± ({percentage:.1f}%)\\n\"\n",
        "                msg += \"\\n\"\n",
        "\n",
        "            # Ù…Ø­Ø¨ÙˆØ¨â€ŒØªØ±ÛŒÙ† ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§\n",
        "            if timeframes:\n",
        "                msg += \"â° **Ù…Ø­Ø¨ÙˆØ¨â€ŒØªØ±ÛŒÙ† ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§:**\\n\"\n",
        "                sorted_tfs = sorted(timeframes.items(), key=lambda x: x[1], reverse=True)\n",
        "                for tf, count in sorted_tfs:\n",
        "                    percentage = (count / total_requests) * 100\n",
        "                    msg += f\"â€¢ `{tf}`: {count} Ø¨Ø§Ø± ({percentage:.1f}%)\\n\"\n",
        "                msg += \"\\n\"\n",
        "\n",
        "            # Ø¢Ø®Ø±ÛŒÙ† Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§\n",
        "            msg += \"ğŸ“ **Ø¢Ø®Ø±ÛŒÙ† 10 Ø¯Ø±Ø®ÙˆØ§Ø³Øª:**\\n\"\n",
        "            recent_lines = [l for l in lines if 'User:' in l and 'Symbol:' in l][-10:]\n",
        "\n",
        "            for line in recent_lines:\n",
        "                try:\n",
        "                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø²Ù…Ø§Ù†\n",
        "                    timestamp = line.split('[')[1].split(']')[0].split(' ')[1]  # ÙÙ‚Ø· Ø³Ø§Ø¹Øª\n",
        "\n",
        "                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ø±Ø¨Ø±\n",
        "                    user_part = line.split('User:')[1].split('(ID:')[0].strip()\n",
        "                    if len(user_part) > 15:\n",
        "                        user_part = user_part[:12] + \"...\"\n",
        "\n",
        "                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ symbol\n",
        "                    symbol_part = line.split('Symbol:')[1].strip()\n",
        "                    if '|' in symbol_part:\n",
        "                        symbol_part = symbol_part.split('|')[0].strip()\n",
        "\n",
        "                    msg += f\"â€¢ `{timestamp}` - {user_part} â†’ `{symbol_part}`\\n\"\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³ÛŒØ³ØªÙ…\n",
        "            msg += \"\\nğŸ“Š **ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…:**\\n\"\n",
        "            resources = monitor_resources()\n",
        "            if resources:\n",
        "                msg += f\"â€¢ Ø­Ø§ÙØ¸Ù‡: {resources.get('memory_percent', 0):.1f}%\\n\"\n",
        "                msg += f\"â€¢ Ú©Ø´: {resources.get('cache_items', 0)} Ø¢ÛŒØªÙ…\\n\"\n",
        "\n",
        "            # Ø¢Ù…Ø§Ø± ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§\n",
        "            msg += \"\\nğŸ¦ **ÙˆØ¶Ø¹ÛŒØª ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§:**\\n\"\n",
        "            for ex_id, state in exchange_data.items():\n",
        "                success_rate = 0\n",
        "                total = state['success_count'] + state['fail_count']\n",
        "                if total > 0:\n",
        "                    success_rate = (state['success_count'] / total) * 100\n",
        "\n",
        "                status_icon = \"âœ…\" if not state['in_cooldown'] else \"â³\"\n",
        "                msg += f\"{status_icon} `{ex_id}`: {success_rate:.0f}% Ù…ÙˆÙÙ‚\\n\"\n",
        "\n",
        "            msg += f\"\\nğŸ• Ø¢Ø®Ø±ÛŒÙ† Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ: {datetime.now().strftime('%H:%M:%S')}\"\n",
        "\n",
        "            await update.message.reply_text(msg, parse_mode='Markdown')\n",
        "            logger.info(f\"ğŸ“Š Ø¢Ù…Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ù…ÛŒÙ† {username} Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± stats_command: {e}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            await update.message.reply_text(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø±: {str(e)[:100]}\")\n",
        "\n",
        "    async def arz_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "        \"\"\"Ø§Ø³Ú©Ù† Ø®ÙˆØ¯Ú©Ø§Ø± 100 Ø§Ø±Ø² Ø¨Ø±ØªØ± Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… 15 Ø¯Ù‚ÛŒÙ‚Ù‡\"\"\"\n",
        "\n",
        "        user = update.effective_user\n",
        "        chat_id = update.effective_chat.id\n",
        "        logger.info(f\"ğŸ“Š Ø¯Ø³ØªÙˆØ± /arz Ø§Ø² {user.username or user.id}\")\n",
        "\n",
        "        # Ù¾ÛŒØ§Ù… Ø´Ø±ÙˆØ¹\n",
        "        start_msg = await update.message.reply_text(\n",
        "            \"ğŸ” Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ù† 100 Ø§Ø±Ø² Ø¨Ø±ØªØ±\\n\\n\"\n",
        "            \"â± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…: 15 Ø¯Ù‚ÛŒÙ‚Ù‡\\n\"\n",
        "            \"ğŸ¯ ØªØ¹Ø¯Ø§Ø¯: 100 Ø§Ø±Ø²\\n\\n\"\n",
        "            \"â³ Ù„Ø·ÙØ§Ù‹ ØµØ¨Ø± Ú©Ù†ÛŒØ¯...\"\n",
        "        )\n",
        "\n",
        "        # Ù„ÛŒØ³Øª 100 Ø§Ø±Ø² Ø¨Ø±ØªØ±\n",
        "        top_coins = [\n",
        "            'BTC/USDT', 'ETH/USDT', 'BNB/USDT', 'XRP/USDT', 'ADA/USDT',\n",
        "            'DOGE/USDT', 'SOL/USDT', 'TRX/USDT', 'DOT/USDT', 'MATIC/USDT',\n",
        "            'LTC/USDT', 'SHIB/USDT', 'AVAX/USDT', 'UNI/USDT', 'LINK/USDT',\n",
        "            'ATOM/USDT', 'XMR/USDT', 'ETC/USDT', 'BCH/USDT', 'XLM/USDT',\n",
        "            'ALGO/USDT', 'FIL/USDT', 'ICP/USDT', 'VET/USDT', 'HBAR/USDT',\n",
        "            'NEAR/USDT', 'APT/USDT', 'QNT/USDT', 'GRT/USDT', 'AAVE/USDT',\n",
        "            'SUI/USDT', 'ARB/USDT', 'OP/USDT', 'INJ/USDT', 'STX/USDT',\n",
        "            'MKR/USDT', 'RUNE/USDT', 'IMX/USDT', 'FTM/USDT', 'FLOW/USDT',\n",
        "            'XTZ/USDT', 'SAND/USDT', 'MANA/USDT', 'AXS/USDT', 'THETA/USDT',\n",
        "            'EOS/USDT', 'EGLD/USDT', 'KSM/USDT', 'ZEC/USDT', 'DASH/USDT',\n",
        "            'COMP/USDT', 'SNX/USDT', 'SUSHI/USDT', 'YFI/USDT', 'CRV/USDT',\n",
        "            '1INCH/USDT', 'BAL/USDT', 'UMA/USDT', 'ENJ/USDT', 'CHZ/USDT',\n",
        "            'BAT/USDT', 'ZIL/USDT', 'OCEAN/USDT', 'REN/USDT', 'CELO/USDT',\n",
        "            'ONT/USDT', 'ICX/USDT', 'ZRX/USDT', 'WAVES/USDT', 'NEO/USDT',\n",
        "            'QTUM/USDT', 'OMG/USDT', 'LRC/USDT', 'IOST/USDT', 'ANT/USDT',\n",
        "            'SC/USDT', 'ZEN/USDT', 'KAVA/USDT', 'BNT/USDT', 'RVN/USDT',\n",
        "            'DGB/USDT', 'SXP/USDT', 'STORJ/USDT', 'KNC/USDT', 'RSR/USDT',\n",
        "            'CELR/USDT', 'REP/USDT', 'HOT/USDT', 'IOTX/USDT', 'WAN/USDT',\n",
        "            'FET/USDT', 'BAND/USDT', 'NKN/USDT', 'ARPA/USDT', 'CTXC/USDT',\n",
        "            'TROY/USDT', 'WIN/USDT', 'COS/USDT', 'PERL/USDT', 'DENT/USDT'\n",
        "        ]\n",
        "\n",
        "        long_signals = []\n",
        "        short_signals = []\n",
        "        neutral_count = 0\n",
        "        processed = 0\n",
        "\n",
        "        logger.info(f\"ğŸš€ Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ {len(top_coins)} Ø§Ø±Ø²...\")\n",
        "\n",
        "        for symbol in top_coins:\n",
        "            try:\n",
        "                processed += 1\n",
        "\n",
        "                # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ§Ù… Ù¾ÛŒØ´Ø±ÙØª Ù‡Ø± 20 Ø§Ø±Ø²\n",
        "                if processed % 20 == 0:\n",
        "                    try:\n",
        "                        await start_msg.edit_text(\n",
        "                            f\"â³ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ... ({processed}/{len(top_coins)})\"\n",
        "                        )\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                logger.info(f\"ğŸ“Š [{processed}/{len(top_coins)}] ØªØ­Ù„ÛŒÙ„ {symbol}...\")\n",
        "\n",
        "                # ØªØ­Ù„ÛŒÙ„ Ø§Ø±Ø²\n",
        "                result = self.analyzer.analyze_symbol(\n",
        "                    symbol=symbol,\n",
        "                    timeframes=['15m']\n",
        "                )\n",
        "\n",
        "                if result and result.direction != 'NEUTRAL':\n",
        "                    signal_data = {\n",
        "                        'symbol': symbol,\n",
        "                        'direction': result.direction,\n",
        "                        'confidence': result.confidence,\n",
        "                        'entry': result.entry_price,\n",
        "                        'sl': result.stop_loss,\n",
        "                        'tp1': result.targets[0] if result.targets else None,\n",
        "                        'tp2': result.targets[1] if len(result.targets) > 1 else None,\n",
        "                        'tp3': result.targets[2] if len(result.targets) > 2 else None,\n",
        "                    }\n",
        "\n",
        "                    if result.direction == 'LONG':\n",
        "                        long_signals.append(signal_data)\n",
        "                        logger.info(f\"   âœ… Ø³ÛŒÚ¯Ù†Ø§Ù„ LONG - Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {result.confidence}%\")\n",
        "                    else:\n",
        "                        short_signals.append(signal_data)\n",
        "                        logger.info(f\"   âœ… Ø³ÛŒÚ¯Ù†Ø§Ù„ SHORT - Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {result.confidence}%\")\n",
        "                else:\n",
        "                    neutral_count += 1\n",
        "                    logger.debug(f\"   âšª Ø®Ù†Ø«ÛŒ ÛŒØ§ Ø¨Ø¯ÙˆÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„\")\n",
        "\n",
        "                # ØªØ§Ø®ÛŒØ± Ø¨Ø±Ø§ÛŒ Rate Limit\n",
        "                await asyncio.sleep(1.5)\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± {symbol}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ confidence\n",
        "        long_signals.sort(key=lambda x: x['confidence'], reverse=True)\n",
        "        short_signals.sort(key=lambda x: x['confidence'], reverse=True)\n",
        "\n",
        "        total_signals = len(long_signals) + len(short_signals)\n",
        "\n",
        "        # Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù… Ø®Ù„Ø§ØµÙ‡\n",
        "        summary = f\"âœ… **Ù†ØªØ§ÛŒØ¬ Ø§Ø³Ú©Ù† 100 Ø§Ø±Ø² (15m)**\\n\\n\"\n",
        "        summary += f\"ğŸ“Š Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø¯Ù‡: {processed}/{len(top_coins)}\\n\"\n",
        "        summary += f\"ğŸ¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ ÛŒØ§ÙØª Ø´Ø¯Ù‡: {total_signals}\\n\"\n",
        "        summary += f\"ğŸŸ¢ LONG: {len(long_signals)}\\n\"\n",
        "        summary += f\"ğŸ”´ SHORT: {len(short_signals)}\\n\"\n",
        "        summary += f\"âšª Ø®Ù†Ø«ÛŒ: {neutral_count}\\n\\n\"\n",
        "\n",
        "        if total_signals == 0:\n",
        "            summary += \"âŒ Ù‡ÛŒÚ† Ø³ÛŒÚ¯Ù†Ø§Ù„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.\"\n",
        "        else:\n",
        "            summary += \"ğŸ“‹ Ù„ÛŒØ³Øª Ú©Ø§Ù…Ù„ Ø¯Ø± Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯...\"\n",
        "\n",
        "        # ÙˆÛŒØ±Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ø´Ø±ÙˆØ¹ Ø¨Ù‡ Ø®Ù„Ø§ØµÙ‡\n",
        "        try:\n",
        "            await start_msg.edit_text(summary, parse_mode='Markdown')\n",
        "        except:\n",
        "            await update.message.reply_text(summary, parse_mode='Markdown')\n",
        "\n",
        "        await asyncio.sleep(1)\n",
        "\n",
        "        # Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ LONG (ØªÙ‚Ø³ÛŒÙ… Ø´Ø¯Ù‡ Ø¨Ù‡ Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ 20 ØªØ§ÛŒÛŒ)\n",
        "        if long_signals:\n",
        "            chunk_size = 20\n",
        "            total_chunks = (len(long_signals) + chunk_size - 1) // chunk_size\n",
        "\n",
        "            for chunk_idx in range(0, len(long_signals), chunk_size):\n",
        "                chunk = long_signals[chunk_idx:chunk_idx + chunk_size]\n",
        "                chunk_number = (chunk_idx // chunk_size) + 1\n",
        "\n",
        "                msg = f\"ğŸŸ¢ **Ø³ÛŒÚ¯Ù†Ø§Ù„ LONG (Ø¨Ø®Ø´ {chunk_number}/{total_chunks}):**\\n\\n\"\n",
        "\n",
        "                for i, sig in enumerate(chunk, start=chunk_idx + 1):\n",
        "                    msg += f\"{i}. {sig['symbol']} - Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {sig['confidence']}%\\n\"\n",
        "\n",
        "                await update.message.reply_text(msg, parse_mode='Markdown')\n",
        "                await asyncio.sleep(0.5)\n",
        "\n",
        "        # Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ SHORT (ØªÙ‚Ø³ÛŒÙ… Ø´Ø¯Ù‡ Ø¨Ù‡ Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ 20 ØªØ§ÛŒÛŒ)\n",
        "        if short_signals:\n",
        "            chunk_size = 20\n",
        "            total_chunks = (len(short_signals) + chunk_size - 1) // chunk_size\n",
        "\n",
        "            for chunk_idx in range(0, len(short_signals), chunk_size):\n",
        "                chunk = short_signals[chunk_idx:chunk_idx + chunk_size]\n",
        "                chunk_number = (chunk_idx // chunk_size) + 1\n",
        "\n",
        "                msg = f\"ğŸ”´ **Ø³ÛŒÚ¯Ù†Ø§Ù„ SHORT (Ø¨Ø®Ø´ {chunk_number}/{total_chunks}):**\\n\\n\"\n",
        "\n",
        "                for i, sig in enumerate(chunk, start=chunk_idx + 1):\n",
        "                    msg += f\"{i}. {sig['symbol']} - Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {sig['confidence']}%\\n\"\n",
        "\n",
        "                await update.message.reply_text(msg, parse_mode='Markdown')\n",
        "                await asyncio.sleep(0.5)\n",
        "\n",
        "        # Ø§Ø±Ø³Ø§Ù„ Ø¬Ø²Ø¦ÛŒØ§Øª 5 Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø±ØªØ± LONG\n",
        "        if long_signals:\n",
        "            await update.message.reply_text(\n",
        "                \"ğŸ† **Ø¬Ø²Ø¦ÛŒØ§Øª 5 Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø±ØªØ± LONG:**\",\n",
        "                parse_mode='Markdown'\n",
        "            )\n",
        "            await asyncio.sleep(0.5)\n",
        "\n",
        "            for sig in long_signals[:5]:\n",
        "                try:\n",
        "                    detail_msg = (\n",
        "                        f\"ğŸŸ¢ **{sig['symbol']}**\\n\\n\"\n",
        "                        f\"ğŸ’¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {sig['confidence']}%\\n\\n\"\n",
        "                        f\"ğŸ’° ÙˆØ±ÙˆØ¯: `{sig['entry']:.8f}`\\n\"\n",
        "                        f\"ğŸ›‘ Ø­Ø¯ Ø¶Ø±Ø±: `{sig['sl']:.8f}`\\n\"\n",
        "                    )\n",
        "\n",
        "                    if sig['tp1']:\n",
        "                        detail_msg += f\"ğŸ¯ Ù‡Ø¯Ù 1: `{sig['tp1']:.8f}`\\n\"\n",
        "                    if sig['tp2']:\n",
        "                        detail_msg += f\"ğŸ¯ Ù‡Ø¯Ù 2: `{sig['tp2']:.8f}`\\n\"\n",
        "                    if sig['tp3']:\n",
        "                        detail_msg += f\"ğŸ¯ Ù‡Ø¯Ù 3: `{sig['tp3']:.8f}`\\n\"\n",
        "\n",
        "                    await update.message.reply_text(detail_msg, parse_mode='Markdown')\n",
        "                    await asyncio.sleep(1)\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ø¬Ø²Ø¦ÛŒØ§Øª {sig['symbol']}: {e}\")\n",
        "\n",
        "        # Ø§Ø±Ø³Ø§Ù„ Ø¬Ø²Ø¦ÛŒØ§Øª 5 Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø±ØªØ± SHORT\n",
        "        if short_signals:\n",
        "            await update.message.reply_text(\n",
        "                \"ğŸ† **Ø¬Ø²Ø¦ÛŒØ§Øª 5 Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø±ØªØ± SHORT:**\",\n",
        "                parse_mode='Markdown'\n",
        "            )\n",
        "            await asyncio.sleep(0.5)\n",
        "\n",
        "            for sig in short_signals[:5]:\n",
        "                try:\n",
        "                    detail_msg = (\n",
        "                        f\"ğŸ”´ **{sig['symbol']}**\\n\\n\"\n",
        "                        f\"ğŸ’¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {sig['confidence']}%\\n\\n\"\n",
        "                        f\"ğŸ’° ÙˆØ±ÙˆØ¯: `{sig['entry']:.8f}`\\n\"\n",
        "                        f\"ğŸ›‘ Ø­Ø¯ Ø¶Ø±Ø±: `{sig['sl']:.8f}`\\n\"\n",
        "                    )\n",
        "\n",
        "                    if sig['tp1']:\n",
        "                        detail_msg += f\"ğŸ¯ Ù‡Ø¯Ù 1: `{sig['tp1']:.8f}`\\n\"\n",
        "                    if sig['tp2']:\n",
        "                        detail_msg += f\"ğŸ¯ Ù‡Ø¯Ù 2: `{sig['tp2']:.8f}`\\n\"\n",
        "                    if sig['tp3']:\n",
        "                        detail_msg += f\"ğŸ¯ Ù‡Ø¯Ù 3: `{sig['tp3']:.8f}`\\n\"\n",
        "\n",
        "                    await update.message.reply_text(detail_msg, parse_mode='Markdown')\n",
        "                    await asyncio.sleep(1)\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ø¬Ø²Ø¦ÛŒØ§Øª {sig['symbol']}: {e}\")\n",
        "\n",
        "        logger.info(\"=\" * 60)\n",
        "        logger.info(f\"âœ… Ø§Ø³Ú©Ù† Ú©Ø§Ù…Ù„ Ø´Ø¯:\")\n",
        "        logger.info(f\"   ğŸ“Š Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø¯Ù‡: {processed}\")\n",
        "        logger.info(f\"   ğŸŸ¢ LONG: {len(long_signals)}\")\n",
        "        logger.info(f\"   ğŸ”´ SHORT: {len(short_signals)}\")\n",
        "        logger.info(f\"   âšª Ø®Ù†Ø«ÛŒ: {neutral_count}\")\n",
        "        logger.info(\"=\" * 60)\n",
        "\n",
        "    async def analyze_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "        \"\"\"Ø¯Ø³ØªÙˆØ± /analyze\"\"\"\n",
        "\n",
        "        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±\n",
        "        user = update.effective_user\n",
        "        user_id = user.id\n",
        "        username = user.username or user.first_name or \"Unknown\"\n",
        "\n",
        "        if not context.args:\n",
        "            await update.message.reply_text(\n",
        "                \"âŒ **ÙØ±Ù…Øª Ù†Ø§Ø¯Ø±Ø³Øª**\\n\\n\"\n",
        "                \"**Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ ØµØ­ÛŒØ­:**\\n\"\n",
        "                \"`/analyze BTC/USDT`\\n\"\n",
        "                \"`/analyze ETH/USDT 1h`\\n\"\n",
        "                \"`/analyze SOL/USDT 4h`\\n\\n\"\n",
        "                \"**ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø±:** 15m, 1h, 4h, 1d\",\n",
        "                parse_mode='Markdown'\n",
        "            )\n",
        "            return\n",
        "\n",
        "        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ symbol\n",
        "        symbol = context.args[0].upper()\n",
        "        if '/' not in symbol:\n",
        "            symbol = f\"{symbol}/USDT\"\n",
        "\n",
        "        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ timeframe\n",
        "        timeframes = ['1h', '4h']  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶\n",
        "        if len(context.args) > 1:\n",
        "            tf = context.args[1].lower()\n",
        "            if tf in ['15m', '1h', '4h', '1d']:\n",
        "                timeframes = [tf]\n",
        "            else:\n",
        "                await update.message.reply_text(\n",
        "                    f\"âŒ **ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… Ù†Ø§Ù…Ø¹ØªØ¨Ø±:** `{tf}`\\n\\n\"\n",
        "                    \"**ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø±:**\\n\"\n",
        "                    \"â€¢ `15m` - Ù¾Ø§Ù†Ø²Ø¯Ù‡ Ø¯Ù‚ÛŒÙ‚Ù‡\\n\"\n",
        "                    \"â€¢ `1h` - ÛŒÚ© Ø³Ø§Ø¹Øª\\n\"\n",
        "                    \"â€¢ `4h` - Ú†Ù‡Ø§Ø± Ø³Ø§Ø¹Øª\\n\"\n",
        "                    \"â€¢ `1d` - Ø±ÙˆØ²Ø§Ù†Ù‡\",\n",
        "                    parse_mode='Markdown'\n",
        "                )\n",
        "                return\n",
        "\n",
        "        # Ø«Ø¨Øª Ù„Ø§Ú¯ ÙØ¹Ø§Ù„ÛŒØª Ú©Ø§Ø±Ø¨Ø±\n",
        "        self.log_user_activity(user_id, username, symbol, f\"analyze_{','.join(timeframes)}\")\n",
        "\n",
        "        # Ù¾ÛŒØ§Ù… Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„\n",
        "        status_msg = await update.message.reply_text(\n",
        "            f\"ğŸ” **Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ {symbol}...**\\n\\n\"\n",
        "            f\"â±ï¸ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…: {', '.join(timeframes)}\\n\"\n",
        "            f\"â³ Ù„Ø·ÙØ§Ù‹ ØµØ¨Ø± Ú©Ù†ÛŒØ¯...\",\n",
        "            parse_mode='Markdown'\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            # Ø§Ù†Ø¬Ø§Ù… ØªØ­Ù„ÛŒÙ„\n",
        "            signals = self.analyzer.analyze_symbol(symbol, timeframes)\n",
        "\n",
        "            # Ø­Ø°Ù Ù¾ÛŒØ§Ù… ÙˆØ¶Ø¹ÛŒØª\n",
        "            await status_msg.delete()\n",
        "\n",
        "            if not signals:\n",
        "                await update.message.reply_text(\n",
        "                    f\"â„¹ï¸ **Ù‡ÛŒÚ† Ø³ÛŒÚ¯Ù†Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} ÛŒØ§ÙØª Ù†Ø´Ø¯**\\n\\n\"\n",
        "                    \"**Ø¯Ù„Ø§ÛŒÙ„ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ:**\\n\"\n",
        "                    \"â€¢ Ø´Ø±Ø§ÛŒØ· Ø¨Ø§Ø²Ø§Ø± Ù…Ù†Ø§Ø³Ø¨ Ù†ÛŒØ³Øª\\n\"\n",
        "                    \"â€¢ ØªØ¶Ø§Ø¯ Ø¨ÛŒÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ LONG Ùˆ SHORT\\n\"\n",
        "                    \"â€¢ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù…ØªØ± Ø§Ø² 60%\\n\"\n",
        "                    \"â€¢ Ø³ØªØ§Ù¾ Ú©Ø§Ù…Ù„ ØªØ´Ú©ÛŒÙ„ Ù†Ø´Ø¯Ù‡\\n\\n\"\n",
        "                    \"ğŸ’¡ **ØªÙˆØµÛŒÙ‡:** Ù…Ù†ØªØ¸Ø± Ø³ØªØ§Ù¾ ÙˆØ§Ø¶Ø­â€ŒØªØ± Ø¨Ù…Ø§Ù†ÛŒØ¯\",\n",
        "                    parse_mode='Markdown'\n",
        "                )\n",
        "                return\n",
        "\n",
        "            # Ø§Ø±Ø³Ø§Ù„ Ù‡Ø± Ø³ÛŒÚ¯Ù†Ø§Ù„\n",
        "            for signal in signals:\n",
        "                await self.send_signal_message(update, signal)\n",
        "                await asyncio.sleep(1)  # ØªØ§Ø®ÛŒØ± Ø¨ÛŒÙ† Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§\n",
        "\n",
        "            # Ø«Ø¨Øª Ù„Ø§Ú¯ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡\n",
        "            logger.info(f\"ğŸ“¤ {len(signals)} Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø±Ø§ÛŒ {username} Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± analyze_command: {e}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "\n",
        "            await update.message.reply_text(\n",
        "                f\"âŒ **Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ {symbol}**\\n\\n\"\n",
        "                f\"**Ø¬Ø²Ø¦ÛŒØ§Øª:** `{str(e)[:150]}`\\n\\n\"\n",
        "                \"Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.\",\n",
        "                parse_mode='Markdown'\n",
        "            )\n",
        "\n",
        "    async def send_signal_message(self, update: Update, signal: TradingSignal):\n",
        "\n",
        "        def escape_markdown_v2(text: str) -> str:\n",
        "            \"\"\"\n",
        "            Escape ØªÙ…Ø§Ù… Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ MarkdownV2\n",
        "            Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø±Ø²Ø±Ùˆ Ø´Ø¯Ù‡ Ø¯Ø± ØªÙ„Ú¯Ø±Ø§Ù…:\n",
        "            _ * [ ] ( ) ~ ` > # + - = | { } . !\n",
        "            \"\"\"\n",
        "            escape_chars = r'_*[]()~`>#+=|{}.!-'\n",
        "            for char in escape_chars:\n",
        "                text = text.replace(char, '\\\\' + char)\n",
        "            return text\n",
        "\n",
        "        # ØªØ¹ÛŒÛŒÙ† Ø§ÛŒÙ…ÙˆØ¬ÛŒ\n",
        "        if signal.direction == \"LONG\":\n",
        "            direction_emoji = \"ğŸŸ¢\"\n",
        "            direction_icon = \"ğŸ“ˆ\"\n",
        "        else:\n",
        "            direction_emoji = \"ğŸ”´\"\n",
        "            direction_icon = \"ğŸ“‰\"\n",
        "\n",
        "        # Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù… Ø§ØµÙ„ÛŒ (Ø¨Ø¯ÙˆÙ† escape - Ø®ÙˆØ¯Ù…Ø§Ù† format Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…)\n",
        "        header = f\"{direction_emoji} *{signal.direction} SIGNAL* {direction_icon}\"\n",
        "        separator = \"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\"\n",
        "\n",
        "        # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ØµÙ„ÛŒ\n",
        "        info_lines = [\n",
        "            f\"*ğŸ’ Symbol:* `{signal.symbol}`\",\n",
        "            f\"*â° Timeframe:* `{signal.timeframe}`\",\n",
        "            f\"*ğŸ¯ Confidence:* `{signal.confidence:.0f}%`\",\n",
        "            f\"*ğŸ“Š Risk/Reward:* `1:{signal.risk_reward:.2f}`\",\n",
        "            f\"*âš ï¸ Risk:* `{signal.risk_percent:.2f}%`\"\n",
        "        ]\n",
        "\n",
        "        # Entry\n",
        "        entry_section = [\n",
        "            \"*ğŸ“ ENTRY ZONE*\",\n",
        "            f\"ğŸ’° *Entry Price:* `{signal.entry_price:.8f}`\"\n",
        "        ]\n",
        "\n",
        "        # Stop Loss\n",
        "        sl_section = [\n",
        "            \"*ğŸ›¡ï¸ STOP LOSS*\",\n",
        "            f\"ğŸš« *Stop Loss:* `{signal.stop_loss:.8f}`\"\n",
        "        ]\n",
        "\n",
        "        # Take Profits\n",
        "        tp_section = [\n",
        "            \"*ğŸ¯ TAKE PROFIT TARGETS*\",\n",
        "            f\"ğŸ¥‡ *TP1 \\\\(1\\\\.5R\\\\):* `{signal.targets[0]:.8f}`\",\n",
        "            f\"ğŸ¥ˆ *TP2 \\\\(2\\\\.5R\\\\):* `{signal.targets[1]:.8f}`\",\n",
        "            f\"ğŸ¥‰ *TP3 \\\\(4\\\\.0R\\\\):* `{signal.targets[2]:.8f}`\"\n",
        "        ]\n",
        "\n",
        "        # ØªØ±Ú©ÛŒØ¨ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù„Ø§\n",
        "        msg_parts = [\n",
        "            header,\n",
        "            separator,\n",
        "            \"\",\n",
        "            \"\\n\".join(info_lines),\n",
        "            \"\",\n",
        "            separator,\n",
        "            \"\\n\".join(entry_section),\n",
        "            \"\",\n",
        "            separator,\n",
        "            \"\\n\".join(sl_section),\n",
        "            \"\",\n",
        "            separator,\n",
        "            \"\\n\".join(tp_section),\n",
        "            \"\",\n",
        "            separator,\n",
        "            \"*ğŸ“‹ SIGNAL REASONS*\",\n",
        "            separator\n",
        "        ]\n",
        "\n",
        "        msg = \"\\n\".join(msg_parts)\n",
        "\n",
        "        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¯Ù„Ø§ÛŒÙ„\n",
        "        reasons_text = \"\"\n",
        "        for i, reason in enumerate(signal.reasons, 1):\n",
        "            # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ùˆ escape Ú©Ø±Ø¯Ù† Ù‡Ø± Ø¯Ù„ÛŒÙ„\n",
        "            clean_reason = reason.replace('âœ…', 'âœ”').replace('âš¡', 'âš ').replace('ğŸ“¦', 'â–ª').replace('ğŸ”Š', 'â–ª')\n",
        "            escaped_reason = escape_markdown_v2(clean_reason)\n",
        "            reasons_text += f\"{i}\\\\. {escaped_reason}\\n\"\n",
        "\n",
        "        msg += \"\\n\" + reasons_text\n",
        "\n",
        "        # Market Context\n",
        "        if signal.market_context:\n",
        "            msg += f\"\\n{separator}\\n\"\n",
        "            msg += f\"*ğŸŒ MARKET CONTEXT*\\n\"\n",
        "            msg += f\"{separator}\\n\"\n",
        "\n",
        "            btc_d = signal.market_context.get('btc_dominance', 0)\n",
        "            btc_trend = signal.market_context.get('btc_trend', 'neutral')\n",
        "            usdt_d = signal.market_context.get('usdt_dominance', 0)\n",
        "            market_phase = signal.market_context.get('market_phase', 'neutral')\n",
        "\n",
        "            # Format Ø¨Ø§ escape\n",
        "            btc_d_str = f\"{btc_d:.2f}\".replace('.', '\\\\.')\n",
        "            usdt_d_str = f\"{usdt_d:.2f}\".replace('.', '\\\\.')\n",
        "            btc_trend_escaped = escape_markdown_v2(btc_trend)\n",
        "            phase_escaped = escape_markdown_v2(market_phase.replace('_', ' '))\n",
        "\n",
        "            msg += f\"â€¢ *BTC\\\\.D:* {btc_d_str}% \\\\({btc_trend_escaped}\\\\)\\n\"\n",
        "            msg += f\"â€¢ *USDT\\\\.D:* {usdt_d_str}%\\n\"\n",
        "            msg += f\"â€¢ *Phase:* {phase_escaped}\\n\"\n",
        "\n",
        "            if 'total_mcap' in signal.market_context:\n",
        "                mcap = signal.market_context['total_mcap']\n",
        "                mcap_str = f\"{mcap/1e12:.2f}\".replace('.', '\\\\.')\n",
        "                msg += f\"â€¢ *Total MCap:* ${mcap_str}T\\n\"\n",
        "\n",
        "        # Position Size\n",
        "        msg += f\"\\n{separator}\\n\"\n",
        "        msg += f\"*ğŸ’¡ POSITION SIZE*\\n\"\n",
        "        msg += f\"{separator}\\n\"\n",
        "        msg += f\"Ø¨Ø§ Ø±ÛŒØ³Ú© 1% Ø³Ø±Ù…Ø§ÛŒÙ‡:\\n\"\n",
        "        msg += f\"`Position = \\\\(Capital Ã— 0\\\\.01\\\\) / Distance\\\\_to\\\\_SL`\\n\"\n",
        "\n",
        "        # Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§\n",
        "        msg += f\"\\n{separator}\\n\"\n",
        "        msg += f\"*âš ï¸ IMPORTANT NOTES*\\n\"\n",
        "        msg += f\"{separator}\\n\"\n",
        "        msg += f\"â€¢ Ù‡Ù…ÛŒØ´Ù‡ Stop Loss Ø±Ø§ Ø±Ø¹Ø§ÛŒØª Ú©Ù†ÛŒØ¯\\n\"\n",
        "        msg += f\"â€¢ Ø­Ø¯Ø§Ú©Ø«Ø± 1\\\\-2% Ø³Ø±Ù…Ø§ÛŒÙ‡ Ø¯Ø± Ù‡Ø± Ù…Ø¹Ø§Ù…Ù„Ù‡\\n\"\n",
        "        msg += f\"â€¢ DYOR \\\\- ØªØ­Ù‚ÛŒÙ‚Ø§Øª Ø´Ø®ØµÛŒ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯\\n\"\n",
        "        msg += f\"â€¢ Ú©Ø§Ù†Ø§Ù„: @finance\\\\_hossein\\n\"\n",
        "\n",
        "        # ØªØ§Ø±ÛŒØ®\n",
        "        timestamp_str = signal.timestamp.strftime('%Y-%m-%d %H:%M:%S')\n",
        "        timestamp_escaped = escape_markdown_v2(timestamp_str)\n",
        "        msg += f\"\\nğŸ“… {timestamp_escaped} UTC\"\n",
        "\n",
        "        # Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù…\n",
        "        try:\n",
        "            await update.message.reply_text(msg, parse_mode='MarkdownV2')\n",
        "            logger.info(\"âœ… Ù¾ÛŒØ§Ù… Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… MarkdownV2: {e}\")\n",
        "\n",
        "            # Fallback: Ø§Ø±Ø³Ø§Ù„ Ù…ØªÙ† Ø³Ø§Ø¯Ù‡ Ø¨Ø¯ÙˆÙ† ÙØ±Ù…Øª\n",
        "            try:\n",
        "                simple_msg = f\"\"\"\n",
        "    {direction_emoji} {signal.direction} SIGNAL {direction_icon}\n",
        "    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "\n",
        "    ğŸ’ Symbol: {signal.symbol}\n",
        "    â° Timeframe: {signal.timeframe}\n",
        "    ğŸ¯ Confidence: {signal.confidence:.0f}%\n",
        "    ğŸ“Š Risk/Reward: 1:{signal.risk_reward:.2f}\n",
        "    âš ï¸ Risk: {signal.risk_percent:.2f}%\n",
        "\n",
        "    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "    ğŸ“ ENTRY ZONE\n",
        "    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "    ğŸ’° Entry: {signal.entry_price:.8f}\n",
        "\n",
        "    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "    ğŸ›¡ï¸ STOP LOSS\n",
        "    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "    ğŸš« Stop Loss: {signal.stop_loss:.8f}\n",
        "\n",
        "    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "    ğŸ¯ TAKE PROFIT TARGETS\n",
        "    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "    ğŸ¥‡ TP1 (1.5R): {signal.targets[0]:.8f}\n",
        "    ğŸ¥ˆ TP2 (2.5R): {signal.targets[1]:.8f}\n",
        "    ğŸ¥‰ TP3 (4.0R): {signal.targets[2]:.8f}\n",
        "\n",
        "    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "    ğŸ“‹ SIGNAL REASONS ({len(signal.reasons)} Ø¯Ù„ÛŒÙ„)\n",
        "    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "    \"\"\"\n",
        "                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¯Ù„Ø§ÛŒÙ„\n",
        "                for i, reason in enumerate(signal.reasons, 1):\n",
        "                    simple_msg += f\"{i}. {reason}\\n\"\n",
        "\n",
        "                # Market Context\n",
        "                if signal.market_context:\n",
        "                    simple_msg += f\"\\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\\n\"\n",
        "                    simple_msg += f\"ğŸŒ MARKET CONTEXT\\n\"\n",
        "                    simple_msg += f\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\\n\"\n",
        "\n",
        "                    btc_d = signal.market_context.get('btc_dominance', 0)\n",
        "                    btc_trend = signal.market_context.get('btc_trend', 'neutral')\n",
        "                    usdt_d = signal.market_context.get('usdt_dominance', 0)\n",
        "                    market_phase = signal.market_context.get('market_phase', 'neutral')\n",
        "\n",
        "                    simple_msg += f\"â€¢ BTC.D: {btc_d:.2f}% ({btc_trend})\\n\"\n",
        "                    simple_msg += f\"â€¢ USDT.D: {usdt_d:.2f}%\\n\"\n",
        "                    simple_msg += f\"â€¢ Phase: {market_phase}\\n\"\n",
        "\n",
        "                # Position Size\n",
        "                simple_msg += f\"\\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\\n\"\n",
        "                simple_msg += f\"ğŸ’¡ POSITION SIZE\\n\"\n",
        "                simple_msg += f\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\\n\"\n",
        "                simple_msg += f\"Ø¨Ø§ Ø±ÛŒØ³Ú© 1% Ø³Ø±Ù…Ø§ÛŒÙ‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ù†ÛŒØ¯\\n\"\n",
        "                simple_msg += f\"Position = (Capital Ã— 0.01) / Distance_to_SL\\n\"\n",
        "\n",
        "                # Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§\n",
        "                simple_msg += f\"\\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\\n\"\n",
        "                simple_msg += f\"âš ï¸ IMPORTANT NOTES\\n\"\n",
        "                simple_msg += f\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\\n\"\n",
        "                simple_msg += f\"â€¢ Ù‡Ù…ÛŒØ´Ù‡ Stop Loss Ø±Ø§ Ø±Ø¹Ø§ÛŒØª Ú©Ù†ÛŒØ¯\\n\"\n",
        "                simple_msg += f\"â€¢ Ø­Ø¯Ø§Ú©Ø«Ø± 1-2% Ø³Ø±Ù…Ø§ÛŒÙ‡ Ø¯Ø± Ù‡Ø± Ù…Ø¹Ø§Ù…Ù„Ù‡\\n\"\n",
        "                simple_msg += f\"â€¢ DYOR - ØªØ­Ù‚ÛŒÙ‚Ø§Øª Ø´Ø®ØµÛŒ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯\\n\"\n",
        "                simple_msg += f\"â€¢ Ú©Ø§Ù†Ø§Ù„: @finance_hossein\\n\"\n",
        "\n",
        "                simple_msg += f\"\\nğŸ“… {signal.timestamp.strftime('%Y-%m-%d %H:%M:%S')} UTC\"\n",
        "\n",
        "                await update.message.reply_text(simple_msg)\n",
        "                logger.info(\"âœ… Ù¾ÛŒØ§Ù… Ø³Ø§Ø¯Ù‡ (fallback) Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯\")\n",
        "\n",
        "            except Exception as e2:\n",
        "                logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø³Ø§Ø¯Ù‡: {e2}\")\n",
        "\n",
        "        # Ø§Ø±Ø³Ø§Ù„ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
        "        if signal.chart_path and os.path.exists(signal.chart_path):\n",
        "            try:\n",
        "                with open(signal.chart_path, 'rb') as photo:\n",
        "                    caption = f\"{signal.symbol} | {signal.timeframe} | {signal.direction} | {signal.confidence:.0f}%\"\n",
        "                    await update.message.reply_photo(photo=photo, caption=caption)\n",
        "                logger.info(f\"âœ… Ù†Ù…ÙˆØ¯Ø§Ø± Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯: {signal.chart_path}\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù†Ù…ÙˆØ¯Ø§Ø±: {e}\")\n",
        "                logger.error(traceback.format_exc())\n",
        "        else:\n",
        "            logger.warning(f\"âš ï¸ ÙØ§ÛŒÙ„ Ù†Ù…ÙˆØ¯Ø§Ø± ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯: {signal.chart_path}\")\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…\"\"\"\n",
        "        if not TELEGRAM_AVAILABLE:\n",
        "            logger.error(\"âŒ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª\")\n",
        "            return\n",
        "\n",
        "        logger.info(\"ğŸš€ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…...\")\n",
        "\n",
        "        try:\n",
        "            self.app = Application.builder().token(self.token).build()\n",
        "\n",
        "            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¯Ø³ØªÙˆØ±Ø§Øª\n",
        "            self.app.add_handler(CommandHandler(\"start\", self.start_command))\n",
        "            self.app.add_handler(CommandHandler(\"help\", self.help_command))\n",
        "            self.app.add_handler(CommandHandler(\"analyze\", self.analyze_command))\n",
        "            self.app.add_handler(CommandHandler(\"stats\", self.stats_command))  # â¬…ï¸ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯\n",
        "            self.app.add_handler(CommandHandler(\"arz\", self.arz_command))  # â¬…ï¸ Ø§ÛŒÙ† Ø®Ø· Ø±Ùˆ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†\n",
        "\n",
        "\n",
        "            logger.info(\"âœ… Ø±Ø¨Ø§Øª Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª\")\n",
        "            logger.info(\"ğŸ“± Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ Ø¯Ø³ØªÙˆØ± /start Ø±Ø§ Ø¯Ø± ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø²Ù†ÛŒØ¯\")\n",
        "\n",
        "            # Ø´Ø±ÙˆØ¹ polling\n",
        "            self.app.run_polling(allowed_updates=Update.ALL_TYPES)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø±Ø¨Ø§Øª: {e}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "\n",
        "\n",
        "# ==================== ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ ====================\n",
        "\n",
        "async def main():\n",
        "    \"\"\"\n",
        "    ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ùˆ Ø§Ø¬Ø±Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡\n",
        "    \"\"\"\n",
        "    logger.info(\"=\"*70)\n",
        "    logger.info(\"ğŸš€ Smart Money Whale Hunter - Professional Edition v2.1\")\n",
        "    logger.info(\"=\"*70)\n",
        "\n",
        "    # ØªØ³Øª Ø¨Ø§ BTC\n",
        "    test_symbol = 'BTC/USDT'\n",
        "    test_timeframes = ['1h', '4h']\n",
        "\n",
        "    logger.info(f\"\\nğŸ§ª ØªØ³Øª Ø³ÛŒØ³ØªÙ… Ø¨Ø§ {test_symbol}\")\n",
        "    logger.info(f\"â±ï¸ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§: {', '.join(test_timeframes)}\\n\")\n",
        "\n",
        "    # Ø§ÛŒØ¬Ø§Ø¯ analyzer\n",
        "    hunter = SmartMoneyWhaleHunter()\n",
        "\n",
        "    try:\n",
        "        # ØªØ­Ù„ÛŒÙ„\n",
        "        signals = hunter.analyze_symbol(test_symbol, test_timeframes)\n",
        "\n",
        "        # Ú¯Ø²Ø§Ø±Ø´ Ù†ØªØ§ÛŒØ¬\n",
        "        if signals:\n",
        "            logger.info(f\"\\n{'='*70}\")\n",
        "            logger.info(f\"âœ… ØªØ³Øª Ù…ÙˆÙÙ‚ - {len(signals)} Ø³ÛŒÚ¯Ù†Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯\")\n",
        "            logger.info(f\"{'='*70}\")\n",
        "\n",
        "            for i, signal in enumerate(signals, 1):\n",
        "                logger.info(f\"\\nğŸ“Š Ø³ÛŒÚ¯Ù†Ø§Ù„ #{i}:\")\n",
        "                logger.info(f\"   Symbol: {signal.symbol}\")\n",
        "                logger.info(f\"   Direction: {signal.direction}\")\n",
        "                logger.info(f\"   Timeframe: {signal.timeframe}\")\n",
        "                logger.info(f\"   Confidence: {signal.confidence:.0f}%\")\n",
        "                logger.info(f\"   Risk/Reward: 1:{signal.risk_reward:.2f}\")\n",
        "                logger.info(f\"   Risk: {signal.risk_percent:.2f}%\")\n",
        "                logger.info(f\"   Entry: {signal.entry_price:.8f}\")\n",
        "                logger.info(f\"   Stop Loss: {signal.stop_loss:.8f}\")\n",
        "                logger.info(f\"   TP1: {signal.targets[0]:.8f}\")\n",
        "        else:\n",
        "            logger.info(f\"\\n{'='*70}\")\n",
        "            logger.info(f\"â„¹ï¸ Ù‡ÛŒÚ† Ø³ÛŒÚ¯Ù†Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ {test_symbol} ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯\")\n",
        "            logger.info(f\"{'='*70}\")\n",
        "            logger.info(\"Ø§ÛŒÙ† Ø·Ø¨ÛŒØ¹ÛŒ Ø§Ø³Øª - Ø³ÛŒØ³ØªÙ… ÙÙ‚Ø· Ø³ØªØ§Ù¾â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§ Ø±Ø§ Ù…ÛŒâ€ŒÙ¾Ø°ÛŒØ±Ø¯\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"\\n{'='*70}\")\n",
        "        logger.error(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª: {e}\")\n",
        "        logger.error(f\"{'='*70}\")\n",
        "        logger.error(traceback.format_exc())\n",
        "\n",
        "    logger.info(f\"\\n{'='*70}\")\n",
        "    logger.info(\"âœ… ØªØ³Øª Ø§ÙˆÙ„ÛŒÙ‡ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯\")\n",
        "    logger.info(\"ğŸ¤– Ø¢Ù…Ø§Ø¯Ù‡ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…\")\n",
        "    logger.info(f\"{'='*70}\\n\")\n",
        "\n",
        "\n",
        "# ==================== Ù†Ù‚Ø·Ù‡ ÙˆØ±ÙˆØ¯ Ø§ØµÙ„ÛŒ ====================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # ØªØ´Ø®ÛŒØµ Ù…Ø­ÛŒØ·\n",
        "        try:\n",
        "            import IPython\n",
        "            # Ù…Ø­ÛŒØ· Jupyter/Colab\n",
        "            import nest_asyncio\n",
        "            nest_asyncio.apply()\n",
        "\n",
        "            logger.info(\"ğŸŒŸ Ù…Ø­ÛŒØ·: Jupyter/Colab\")\n",
        "\n",
        "            # Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øª\n",
        "            import asyncio\n",
        "            loop = asyncio.get_event_loop()\n",
        "            loop.run_until_complete(main())\n",
        "\n",
        "            # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø¨Ø§Øª\n",
        "            logger.info(\"\\n\" + \"=\"*70)\n",
        "            logger.info(\"ğŸ¤– Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…...\")\n",
        "            logger.info(\"=\"*70)\n",
        "\n",
        "            bot = TelegramBot(TELEGRAM_BOT_TOKEN, TELEGRAM_CHANNEL_ID)\n",
        "\n",
        "            # âš ï¸ ØªØºÛŒÛŒØ± Ø§ÛŒÙ†Ø¬Ø§ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² run_polling Ø¨Ø¯ÙˆÙ† Ø¨Ø³ØªÙ† loop\n",
        "            try:\n",
        "                bot.app = Application.builder().token(bot.token).build()\n",
        "                bot.app.add_handler(CommandHandler(\"start\", bot.start_command))\n",
        "                bot.app.add_handler(CommandHandler(\"help\", bot.help_command))\n",
        "                bot.app.add_handler(CommandHandler(\"analyze\", bot.analyze_command))\n",
        "                bot.app.add_handler(CommandHandler(\"stats\", bot.stats_command))  # â¬…ï¸ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯\n",
        "                bot.app.add_handler(CommandHandler(\"arz\", bot.arz_command))  # â¬…ï¸ Ø§ÛŒÙ† Ø®Ø· Ø±Ùˆ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†\n",
        "\n",
        "\n",
        "                logger.info(\"âœ… Ø±Ø¨Ø§Øª Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª\")\n",
        "                logger.info(\"ğŸ“± Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ Ø¯Ø³ØªÙˆØ± /start Ø±Ø§ Ø¯Ø± ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø²Ù†ÛŒØ¯\")\n",
        "\n",
        "                # Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø¯ÙˆÙ† Ø¨Ø³ØªÙ† loop\n",
        "                bot.app.run_polling(allowed_updates=Update.ALL_TYPES, close_loop=False)\n",
        "\n",
        "            except KeyboardInterrupt:\n",
        "                logger.info(\"\\nâ¹ï¸ Ø±Ø¨Ø§Øª ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯\")\n",
        "\n",
        "        except ImportError:\n",
        "            # Ù…Ø­ÛŒØ· Python Ù…Ø¹Ù…ÙˆÙ„ÛŒ\n",
        "            logger.info(\"ğŸ–¥ï¸ Ù…Ø­ÛŒØ·: Python Standard\")\n",
        "\n",
        "            import asyncio\n",
        "            asyncio.run(main())\n",
        "\n",
        "            bot = TelegramBot(TELEGRAM_BOT_TOKEN, TELEGRAM_CHANNEL_ID)\n",
        "            bot.run()\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"\\nâŒ Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ: {e}\")\n",
        "        logger.error(traceback.format_exc())\n",
        "\n",
        "    finally:\n",
        "        logger.info(\"\\nğŸ‘‹ Ø®Ø¯Ø§Ø­Ø§ÙØ¸!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfwwJQ4Tuv4z",
        "outputId": "db824c19-7008-436f-873f-cce2734ebbcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ...\n",
            "ğŸ¨ Ù†ØµØ¨ Kaleido...\n",
            "âœ… Kaleido Ù†ØµØ¨ Ø´Ø¯\n",
            "ğŸ”§ Ù†ØµØ¨ ØªÙ„Ú¯Ø±Ø§Ù…...\n",
            "âœ… Ù†ØµØ¨ Ú©Ø§Ù…Ù„ Ø´Ø¯\n",
            "\n",
            "âœ… ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯\n",
            "ğŸŒŸ Ù…Ø­ÛŒØ· Google Colab\n",
            "ğŸ“‚ BASE_DIR: /content/drive/MyDrive/smart_money_whale_hunter\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:   âš ï¸ BYBIT: Ù…Ø´Ú©Ù„ Ø´Ø¨Ú©Ù‡ - bybit GET https://api.bybit.com/v5/market/time 403 Forbidden <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML\n",
            "WARNING:__main__:   âš ï¸ HUOBI: Ù…Ø´Ú©Ù„ Ø´Ø¨Ú©Ù‡ - huobi GET https://api.hbdm.com/linear-swap-api/v1/swap_contract_info?business_type=all\n",
            "WARNING:__main__:\n",
            "âš ï¸ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ ØºÛŒØ±ÙØ¹Ø§Ù„:\n",
            "WARNING:__main__:   â€¢ BYBIT\n",
            "WARNING:__main__:   â€¢ HUOBI\n",
            "WARNING:__main__:âš ï¸ ØªØ¶Ø§Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯:\n",
            "WARNING:__main__:   LONG Score: 35\n",
            "WARNING:__main__:   SHORT Score: 50\n",
            "WARNING:__main__:   Ø§Ø®ØªÙ„Ø§Ù: 15 (Ø­Ø¯Ø§Ù‚Ù„ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²: 25)\n",
            "WARNING:__main__:   Ù†ØªÛŒØ¬Ù‡: Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙˆØ§Ø¶Ø­ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ - Ù…Ù†ØªØ¸Ø± Ø³ØªØ§Ù¾ Ø¨Ù‡ØªØ±\n",
            "WARNING:__main__:âš ï¸ SL Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ SHORT - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ATR\n",
            "WARNING:__main__:   âš ï¸ BYBIT: Ù…Ø´Ú©Ù„ Ø´Ø¨Ú©Ù‡ - bybit GET https://api.bybit.com/v5/market/time 403 Forbidden <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML\n",
            "WARNING:__main__:   âš ï¸ HUOBI: Ù…Ø´Ú©Ù„ Ø´Ø¨Ú©Ù‡ - huobi GET https://api.hbdm.com/linear-swap-api/v1/swap_contract_info?business_type=all\n",
            "WARNING:__main__:\n",
            "âš ï¸ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ ØºÛŒØ±ÙØ¹Ø§Ù„:\n",
            "WARNING:__main__:   â€¢ BYBIT\n",
            "WARNING:__main__:   â€¢ HUOBI\n",
            "WARNING:__main__:   âš ï¸ BYBIT: Ù…Ø´Ú©Ù„ Ø´Ø¨Ú©Ù‡ - bybit GET https://api.bybit.com/v5/market/time 403 Forbidden <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML\n",
            "WARNING:__main__:   âš ï¸ HUOBI: Ù…Ø´Ú©Ù„ Ø´Ø¨Ú©Ù‡ - huobi GET https://api.hbdm.com/linear-swap-api/v1/swap_contract_info?business_type=all\n",
            "WARNING:__main__:\n",
            "âš ï¸ ØµØ±Ø§ÙÛŒâ€ŒÙ‡Ø§ÛŒ ØºÛŒØ±ÙØ¹Ø§Ù„:\n",
            "WARNING:__main__:   â€¢ BYBIT\n",
            "WARNING:__main__:   â€¢ HUOBI\n",
            "ERROR:__main__:âŒ Ø®Ø·Ø§ Ø¯Ø± BTC/USDT: 'list' object has no attribute 'direction'\n",
            "ERROR:__main__:âŒ Ø®Ø·Ø§ Ø¯Ø± ETH/USDT: 'list' object has no attribute 'direction'\n",
            "WARNING:__main__:âš ï¸ ØªØ¶Ø§Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯:\n",
            "WARNING:__main__:   LONG Score: 75\n",
            "WARNING:__main__:   SHORT Score: 70\n",
            "WARNING:__main__:   Ø§Ø®ØªÙ„Ø§Ù: 5 (Ø­Ø¯Ø§Ù‚Ù„ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²: 25)\n",
            "WARNING:__main__:   Ù†ØªÛŒØ¬Ù‡: Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙˆØ§Ø¶Ø­ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ - Ù…Ù†ØªØ¸Ø± Ø³ØªØ§Ù¾ Ø¨Ù‡ØªØ±\n",
            "WARNING:__main__:âš ï¸ ØªØ¶Ø§Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯:\n",
            "WARNING:__main__:   LONG Score: 45\n",
            "WARNING:__main__:   SHORT Score: 65\n",
            "WARNING:__main__:   Ø§Ø®ØªÙ„Ø§Ù: 20 (Ø­Ø¯Ø§Ù‚Ù„ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²: 25)\n",
            "WARNING:__main__:   Ù†ØªÛŒØ¬Ù‡: Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙˆØ§Ø¶Ø­ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ - Ù…Ù†ØªØ¸Ø± Ø³ØªØ§Ù¾ Ø¨Ù‡ØªØ±\n",
            "WARNING:__main__:âš ï¸ ØªØ¶Ø§Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯:\n",
            "WARNING:__main__:   LONG Score: 60\n",
            "WARNING:__main__:   SHORT Score: 80\n",
            "WARNING:__main__:   Ø§Ø®ØªÙ„Ø§Ù: 20 (Ø­Ø¯Ø§Ù‚Ù„ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²: 25)\n",
            "WARNING:__main__:   Ù†ØªÛŒØ¬Ù‡: Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙˆØ§Ø¶Ø­ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ - Ù…Ù†ØªØ¸Ø± Ø³ØªØ§Ù¾ Ø¨Ù‡ØªØ±\n",
            "WARNING:__main__:âš ï¸ ØªØ¶Ø§Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯:\n",
            "WARNING:__main__:   LONG Score: 70\n",
            "WARNING:__main__:   SHORT Score: 65\n",
            "WARNING:__main__:   Ø§Ø®ØªÙ„Ø§Ù: 5 (Ø­Ø¯Ø§Ù‚Ù„ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²: 25)\n",
            "WARNING:__main__:   Ù†ØªÛŒØ¬Ù‡: Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙˆØ§Ø¶Ø­ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ - Ù…Ù†ØªØ¸Ø± Ø³ØªØ§Ù¾ Ø¨Ù‡ØªØ±\n",
            "ERROR:__main__:âŒ Ø®Ø·Ø§ Ø¯Ø± SOL/USDT: 'list' object has no attribute 'direction'\n",
            "WARNING:__main__:âš ï¸ ØªØ¶Ø§Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯:\n",
            "WARNING:__main__:   LONG Score: 70\n",
            "WARNING:__main__:   SHORT Score: 50\n",
            "WARNING:__main__:   Ø§Ø®ØªÙ„Ø§Ù: 20 (Ø­Ø¯Ø§Ù‚Ù„ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²: 25)\n",
            "WARNING:__main__:   Ù†ØªÛŒØ¬Ù‡: Ø³ÛŒÚ¯Ù†Ø§Ù„ ÙˆØ§Ø¶Ø­ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ - Ù…Ù†ØªØ¸Ø± Ø³ØªØ§Ù¾ Ø¨Ù‡ØªØ±\n",
            "ERROR:__main__:âŒ Ø®Ø·Ø§ Ø¯Ø± DOT/USDT: 'list' object has no attribute 'direction'\n",
            "WARNING:__main__:âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ markets bybit: bybit GET https://api.bybit.com/v5/market/instrume\n",
            "WARNING:__main__:âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ markets bybit: bybit GET https://api.bybit.com/v5/market/instrume\n",
            "WARNING:__main__:âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ markets bybit: bybit GET https://api.bybit.com/v5/market/instrume\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}